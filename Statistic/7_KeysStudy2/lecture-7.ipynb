{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qB1egUSX0gH-"
   },
   "source": [
    "# Кейс-стади -2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "01apPJT-zhCm"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import t\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "import io\n",
    "import requests\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "from scipy.stats import pearsonr\n",
    "import ssl\n",
    "# следующая строчка подключает сертификат для защищенного соединения\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UB_povh6hYuU"
   },
   "source": [
    "# Байесовский метод решения задачи классификации.\n",
    "\n",
    "Лучшим другом аналитика данных является теорема Байеса, которая позволяет \"переставить\" условные вероятности местами. Пусть нужно узнать вероятность не коего события E, зависящего от наступления некоего другого события F, причем в наличии имеется лишь информация о вероятности события F, зависящего от наступления события E. Двукратное применение (в силу симметрии) определения условной вероятности даст формулу Байеса:\n",
    "\n",
    "\n",
    "$$P(A\\mid B) = \\frac{P(B\\mid A) P(A)}{P(B)}$$\n",
    "\n",
    "где $P(A\\mid B)$ - вероятность наступления события A при условии наличия события B\n",
    "\n",
    "\n",
    "Если событие B разложить на два взаимоисключающих события B при условии A и B при условии $\\bar{A}$, то событие P(B) можно представить как сумма вероятностей наступления событий $P(B\\mid A)$ и  $P(B\\mid \\bar{A})$, тогда формула вероятности примет вид:\n",
    "\n",
    "$$P(A\\mid B) = \\frac{P(B\\mid A) P(A)}{P(B\\mid A)P(A) + P(B\\mid \\bar{A})P(\\bar{A})}$$\n",
    "\n",
    "\n",
    "Если события независимы:\n",
    "\n",
    "$$P(A\\mid B) = P(A)P(B)$$\n",
    "\n",
    "Если события зависимы, и при этом вероятность B не равна нулю, то \n",
    "\n",
    "$$P(A\\mid B) = \\frac{P(A, B) }{P(B)}$$\n",
    "\n",
    "\n",
    "Под этим подразумевается вероятность наступления события A при условии, что известно о наступлении события B.\n",
    "\n",
    "В случае независимости двух переменных формула принимает вид:\n",
    "\n",
    "$$P(A\\mid B) = P(A)$$\n",
    "\n",
    "\n",
    "означает, что наличие наступления события B не дает нам никакой информации о наступлении события A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задача. \n",
    "**Определить есть ли болезнь сердца у пациента с определенными показателями.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Датасет больных сердечно-сосудистыми заболеваниями"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Источник: https://www.kaggle.com/sulianova/cardiovascular-disease-dataset"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Data description\n",
    "There are 3 types of input features:\n",
    "\n",
    "Objective: factual information;\n",
    "Examination: results of medical examination;\n",
    "Subjective: information given by the patient.\n",
    "Features:\n",
    "\n",
    "Age | Objective Feature | age | int (days)\n",
    "Height | Objective Feature | height | int (cm) |\n",
    "Weight | Objective Feature | weight | float (kg) |\n",
    "Gender | Objective Feature | gender | categorical code |\n",
    "Systolic blood pressure | Examination Feature | ap_hi | int |\n",
    "Diastolic blood pressure | Examination Feature | ap_lo | int |\n",
    "Cholesterol | Examination Feature | cholesterol | 1: normal, 2: above normal, 3: well above normal |\n",
    "Glucose | Examination Feature | gluc | 1: normal, 2: above normal, 3: well above normal |\n",
    "Smoking | Subjective Feature | smoke | binary |\n",
    "Alcohol intake | Subjective Feature | alco | binary |\n",
    "Physical activity | Subjective Feature | active | binary |\n",
    "Presence or absence of cardiovascular disease | Target Variable | cardio | binary |\n",
    "All of the dataset values were collected at the moment of medical examination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>69995</th>\n",
       "      <td>99993</td>\n",
       "      <td>19240</td>\n",
       "      <td>2</td>\n",
       "      <td>168</td>\n",
       "      <td>76.0</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69996</th>\n",
       "      <td>99995</td>\n",
       "      <td>22601</td>\n",
       "      <td>1</td>\n",
       "      <td>158</td>\n",
       "      <td>126.0</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69997</th>\n",
       "      <td>99996</td>\n",
       "      <td>19066</td>\n",
       "      <td>2</td>\n",
       "      <td>183</td>\n",
       "      <td>105.0</td>\n",
       "      <td>180</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69998</th>\n",
       "      <td>99998</td>\n",
       "      <td>22431</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>72.0</td>\n",
       "      <td>135</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69999</th>\n",
       "      <td>99999</td>\n",
       "      <td>20540</td>\n",
       "      <td>1</td>\n",
       "      <td>170</td>\n",
       "      <td>72.0</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id    age  gender  height  weight  ap_hi  ap_lo  cholesterol  gluc  \\\n",
       "69995  99993  19240       2     168    76.0    120     80            1     1   \n",
       "69996  99995  22601       1     158   126.0    140     90            2     2   \n",
       "69997  99996  19066       2     183   105.0    180     90            3     1   \n",
       "69998  99998  22431       1     163    72.0    135     80            1     2   \n",
       "69999  99999  20540       1     170    72.0    120     80            2     1   \n",
       "\n",
       "       smoke  alco  active  cardio  \n",
       "69995      1     0       1       0  \n",
       "69996      0     0       1       1  \n",
       "69997      0     1       0       1  \n",
       "69998      0     0       0       1  \n",
       "69999      0     0       1       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url=\"http://yustiks.ru/dataset/cardio_train.csv\"\n",
    "data=pd.read_csv(url,sep=\";\")\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сколько человек в таблице всего:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.id.unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Визуализируем несколько взаимосвязей между переменными"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Взаимосвязь между переменной weight и ap_hi {Systolic blood pressure}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX8AAAD3CAYAAAD10FRmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAdvElEQVR4nO3dcXRc5Xnn8e/MyJYwlSUSjJx0waILPPFmD7BAcRMj43NwcB2H0NI9W28OyUnYJlC7SaA0QByCCaUktDFpSHApJKzTNO5uC+E0kCiYlJYIH4KzrIGSKI/BxKFbkAIE2QpGijSa/WPuiNH4zmhmrmbmyvf3+WvmnXdGz4xmfvfe97733lQul0NERJIl3eoCRESk+RT+IiIJpPAXEUkghb+ISAIp/EVEEqit1QVUa2pqKpfNxnNmUiaTIq61geqLSvVFo/qii1LjggWZl4Elpe3zJvyz2RwjI4daXUao7u5Fsa0NVF9Uqi8a1RddlBqXLOn8WVi7hn1ERBJI4S8ikkAKfxGRBFL4i4gkkMJfRCSB5s1sH5l/+geH2Tawn+HRcXo629nY18u65T2tLktEqDL8zWwFcLO7rzaz44A7gWOADPABd99nZh8GLgUmgRvd/X4zOxbYARwFvAB8yN0PhfWd83cmLdU/OMxNO59hbHIKgKHRcW7a+QyAFgAiMTDrsI+ZXQV8BegImv4c+Ia7rwKuBd5mZkuBjwErgbXAZ82sHbgO2OHufcAe4NIKfeUIsm1g/3TwF4xNTrFtYH9rChKRGapZ898HXAR8Pbi/EnjKzL4H7Ac+DpwH7HL3cWDczJ4FTgXOAW4Kntcf3N5Xpu8PKxWRyaTo7l5Uw1trnkwmHdvaoDX1DY+Ol20vrUWfXzSqL5q41weNqXHW8Hf3e8yst6ipF3jV3deY2XXA1cBe4EBRn1GgC1hc1B7WVtxekY7wrV8r6uvpbGcoZAHQ09l+WC36/KJRfdHEvT6IfIRvaHs9s31eAb4V3L4POAs4CBT/hU5gpKQ9rK24XY4gG/t66Wib+fXqaEuzsa+3NQWJyAz1hP8jwLuD26uAHwG7gT4z6zCzLmA58DSwq6jvOmCgQl85gqxb3sPm809maWc7KWBpZzubzz9ZO3tFYqKeqZ5XAl8xsz8kP3zzPnd/1cxuJR/uaeBT7j5mZjcCXwtm97wc9H0trO+cvBuJlXXLexT2IjGVmi8XcJ+YyObiOi4X9zFD1ReN6otG9UUXccz/cfLD8zPoCF8RkQRS+IuIJJDCX0QkgRT+IiIJpPAXEUkghb+ISAIp/EVEEkjhLyKSQAp/EZEEUviLiCSQwl9EJIEU/iIiCaTwFxFJIIW/iEgCKfxFRBJI4S8ikkBVXcnLzFYAN7v76qK29wEfdfd3BPc/DFwKTAI3uvv9ZnYssAM4CngB+JC7HwrrO4fvSZqkf3CYbQP7GR4dp6eznY19vaFX7irXL6wdqOo1RSSaWcPfzK4C3g+8VtR2OvA/gFRwfynwMfJXi+kAHjGzB4HrgB3uvt3MrgEuNbO/C+vr7uNz+s6kofoHh7lp5zOMTU4BMDQ6zk07nwGYEdbl+j357wf49o9+PqP9hn4nlUoxMZWr+JoiEl01wz77gIsKd8zszcDngMuL+pwN7HL3cXc/ADwLnAqcA3w36NMPrKnQV+aRbQP7p4O7YGxyim0D+6vqd+9TQ4e1T+aYDv5Kryki0c265u/u95hZL4CZZYCvAlcArxd1W0z+Yu4Fo0BXSXtYW3F7RZlMiu7uRbN1a4lMJh3b2qAx9Q2Phm+oDY+Oz/hb5fpN1XDp6NLXbLYk/n/nkuqLrhE1VjXmX+RM4GTgr8gP2fwnM/tL4CGgs6hfJzACHAxuvx7SVtq3omw2F9uLLMf9AtCNqK+ns52hkGDv6Wyf8bfK9Uunql8AlL5msyXx/zuXVF90ES/gHtpe02wfd9/t7m8PdvxuAH7s7pcDu4E+M+swsy5gOfA0sAt4d/D0dcBAhb4yj2zs66WjbebXp6MtPb3TdrZ+v3vq0sPa21KwIJ2a9TVFJLpa1/xDufuQmd1KPtzTwKfcfczMbgS+FszueRl4n7u/FtZ3LuqQ5insgJ1tZk6lfqf9epdm+4i0SCqXq2HwtYUmJrK5uG6axX2zUfVFo/qiUX3RRRz2eZz87MoZdJCXiEgCKfxFRBJI4S8ikkAKfxGRBJqT2T4iUXzryRf4iwd83s3wqfbcRiJxpPCXluofHOamB59hbKLyOYLiptpzG4nElYZ9pKW2DeyfDv6C+XA+n2rPbSQSVwp/aalK5wiKs/lat0iBwl9aqqezvab2uJivdYsUKPylpTb29dKxYPZzBMVNtec2Eokr7fCVllq3vIejF7XPu9k+1Z7bSCSuFP7Scu897a2sWtbd6jJqtm55j8Je5i0N+4iIJJDCX0QkgRT+IiIJpPAXEUkghb+ISAJVNdvHzFYAN7v7ajM7HfgSkAXGgQ+4+3BwqcZLgUngRne/38yOBXYARwEvAB9y90Nhfef8nYmISFmzrvmb2VXAV4COoOmLwEeDi7h/E7jazJYCHwNWAmuBz5pZO3AdsMPd+4A9wKUV+oqISJNUs+a/D7gI+Hpwf4O7v1j0/DHgbGCXu48D42b2LHAqcA5wU9C3P7i9r0zfH1YqIpNJ0d29qOo31kyZTDq2tYHqi0r1RaP6omtEjbOGv7vfY2a9RfdfBDCzdwJ/BKwivwZ/oOhpo0AXsLioPaytuL2ibDYX24ssx/0C0KovGtUXjeqLLuIF3EPb69rha2a/D9wOrHf3l4CDQPFf6ARGStrD2orbRUSkSWo+vYOZXUx+Z+1qd/9F0Lwb+DMz6wDageXA08Au4N3AdmAdMFChr8gMulKWSOPUtOZvZhngVvJr6980s38xs8+4+1DQPgA8BHzK3ceAG4ENZrYLeAfw5Qp9RaYVrpQ1NDpOjjeulNU/ONzq0kSOCKlcLtfqGqoyMZHNxXVcLu5jhvOxvgvueIyhkAujLO1s576PrGhWacD8/PziRPVFF3HM/3HgrNJ2HeQlsaQrZYk0lsJfYklXyhJpLIW/xJKulCXSWLqYi9StkbNxdKUskcZS+EtdCrNxxiangDdm4wBzugBQ2Is0hoZ9pC7bBvZPB3/B2OQU2wb2t6YgEamJwl/qotk4IvObwl/qotk4IvObwl/qotk4IvObdvhKXTQbR2R+U/hL3TQbR2T+0rCPiEgCKfxFRBJI4S8ikkAKfxGRBFL4i4gkUFWzfcxsBXCzu682s5PIX5YxR/7yi5vcfcrMtgDrgUngcnffXUvfOX5fIiJSwaxr/mZ2FfAVoCNougW41t37gBRwoZmdAZwLrAA2ALfV0VdERJqkmmGffcBFRffPBB4ObvcDa4BzgJ3unnP354E2M1tSY18REWmSWYd93P0eM+stakq5e+HCv6NAF7AYeKWoT6G9lr4vVaojk0nR3b1otnJbIpNJx7Y2UH1Rqb5oVF90jaixniN8i8/j2wmMAAeD26XttfStKJvNxfYiy3G/ALTqi0b1RaP6oot4AffQ9npm++wxs9XB7XXAALALWGtmaTM7AUi7+8s19hURkSapZ83/SuBOM1sIDAJ3u3vWzAaAR8kvUDbV0VdERJoklcvlZu8VAxMT2VxcN83ivtmo+qJRfdGovugiDvs8DpxV2q6DvEREEkjhLyKSQAp/EZEEUviLiCSQwl9EJIEU/iIiCaTwFxFJIIW/iEgCKfxFRBJI4S8ikkAKfxGRBFL4i4gkkMJfRCSBFP4iIgmk8BcRSSCFv4hIAin8RUQSqJ7LOGJmC4CvAb1AFvgwMAlsB3LA08Amd58ysy3A+uDxy919t5mdFNY30jsREZGq1bvm/26gzd3fCdwA/BlwC3Ctu/cBKeBCMzsDOBdYAWwAbguef1jf+t+CiIjUqq41f2Av0GZmaWAxMAH8FvBw8Hg/cD7gwE53zwHPm1mbmS0Bzgzpe2+lP5jJpOjuXlRnuY2VyaRjWxuovqhUXzSqL7pG1Fhv+P+S/JDPT4BjgfcAq4KQBxgFusgvGF4pel6hPRXSt6JsNhfbiyzH/QLQqi8a1ReN6osu4gXcQ9vrHfa5AnjA3U8BTiM//r+w6PFOYAQ4GNwubZ8KaRMRkSapN/xfBQ4Et38BLAD2mNnqoG0dMADsAtaaWdrMTgDS7v5ymb4iItIk9Q77fAG4y8wGyK/xbwb+D3CnmS0EBoG73T0b9HmU/IJmU/D8K0v7RngPIiJSo7rC391/Cfy3kIfODel7PXB9SdvesL4iItIcOshLRCSBFP4iIgmk8BcRSSCFv4hIAin8RUQSSOEvIpJACn8RkQRS+IuIJJDCX0QkgRT+IiIJpPAXEUkghb+ISAIp/EVEEkjhLyKSQAp/EZEEUviLiCRQvVfywsw+CbyX/JW8tgEPA9uBHPA0sMndp8xsC7AemAQud/fdZnZSWN8I70NERGpQ15p/cP3ddwIryV+R63jgFuBad+8DUsCFZnZG8PgKYANwW/ASh/WN8B5ERKRG9Q77rAX+FbgXuA+4HziT/No/QD+wBjgH2OnuOXd/HmgzsyVl+oqISJPUO+xzLLAMeA9wIvAtIO3uueDxUaALWAy8UvS8QnsqpG9FmUyK7u5FdZbbWJlMOra1geqLSvVFo/qia0SN9Yb/K8BP3P1XgJvZGPmhn4JOYAQ4GNwubZ8Kaasom80xMnKoznIbq7t7UWxrA9UXleqLRvVFF6XGJUs6Q9vrHfZ5BPhtM0uZ2VuBo4F/CvYFAKwDBoBdwFozS5vZCeS3Dl4G9oT0FRGRJqlrzd/d7zezVcBu8guQTcBPgTvNbCEwCNzt7lkzGwAeLeoHcGVp32hvQ0REapHK5XKz94qBiYlsLq6bZnHfbFR90ai+aFRfdBGHfR4Hzipt10FeIiIJpPAXEUkghb+ISAIp/EVEEkjhLyKSQAp/EZEEUviLiCSQwl9EJIEU/iIiCaTwFxFJIIW/iEgCKfxFRBJI4S8ikkAKfxGRBFL4i4gkkMJfRCSBFP4iIglU7wXcATCz44DHgXcBk8B2IAc8DWxy9ykz2wKsDx6/3N13m9lJYX2j1CIiItWre83fzBYAfw28HjTdAlzr7n1ACrjQzM4AzgVWABuA28r1rbcOERGpXZQ1/88DtwOfDO6fCTwc3O4Hzgcc2OnuOeB5M2szsyVl+t5b6Y9lMim6uxdFKLdxMpl0bGsD1ReV6otG9UXXiBrrCn8z+yDwkrs/YGaF8E8FIQ8wCnQBi4FXip5aaA/rW1E2m4vtRZbjfgFo1ReN6otG9UUX8QLuoe31rvlfAuTMbA1wOvA3wHFFj3cCI8DB4HZp+1RIm4iINEldY/7uvsrdz3X31cATwAeAfjNbHXRZBwwAu4C1ZpY2sxOAtLu/DOwJ6SsiIk0SabZPiSuBO81sITAI3O3uWTMbAB4lv6DZVK7vHNYhIiKziBz+wdp/wbkhj18PXF/Stjesr4iINIcO8hIRSSCFv4hIAin8RUQSSOEvIpJACn8RkQRS+IuIJJDCX0QkgRT+IiIJpPAXEUkghb+ISAIp/EVEEkjhLyKSQAp/EZEEUviLiCSQwl9EJIEU/iIiCVTvBdwXAHcBvUA7cCPwY2A7kAOeBja5+5SZbQHWA5PA5e6+28xOCusb6Z3IvNI/OMy2gf0Mj47zlq4OLlu5jHXLe1pdlkhi1LvmfzHwirv3kb8G75eBW4Brg7YUcKGZnUH+il0rgA3AbcHzD+tb/1uQ+aZ/cJibdj7D0Og4OeCFA2PctPMZ+geHW12aSGLUG/7/AHy66P4kcCbwcHC/H1gDnAPsdPecuz8PtJnZkjJ9JSG2DexnbHLmht7Y5BTbBva3piCRBKpr2MfdfwlgZp3kL75+LfB5d88FXUaBLmAx8ErRUwvtqZC+FWUyKbq7F9VTbsNlMunY1gbxq294dLxse5zqLIjb51dK9UUT9/qgMTXWfQF3MzseuBfY5u47zOzPix7uBEaAg8Ht0vapkLaKstkcIyOH6i23obq7F8W2NohffT2d7QyFLAB6Otsj1Vm8H6Gns52Nfb1zsh8hbp9fKdUXTdzrg2g1LlnSGdpe17CPmfUAO4Gr3f2uoHmPma0Obq8DBoBdwFozS5vZCUDa3V8u01cSYmNfLx1tM796HW1pNvb11v2apfsRhkbHtR9BpIJ61/w3A8cAnzazwtj/x4FbzWwhMAjc7e5ZMxsAHiW/oNkU9L0SuLO4b71vQOaH0rXy9W8/jl3PvTpns30q7UfQLCKRw6VyudzsvWJgYiKbi+umWdw3GxtdX//gMFsf2seBsUkAFrdn+JPzTpoO3cJaeXE4d7SlpxcAQ6PjpFMwlYOujjZyuRyj49nQoZtyQztnb/0+Yd/kFLD7ylWR3l/S/79Rqb7oIg77PA6cVdpe95i/JEu50O0fHOZPv7uXiak3ovfgeJYb+h2Adct7yq6V3/Pk0PT9wtMLCxB4Y+im8DqlC5HixyvtRxCRwyn8paxC4JeGanHobhvYPyP4CyZzcH2/s+U7HrpGXq3ioZtKQzsb+3pDty6i7EcQOZIp/CVU2FBNsULolpu2CW+szUdV+BuVpogWhoYaMdtH5Eik8JdQYWvZpYZGx1ncnuHgeLahtSzuyH9NZxvaWbe8R2EvUiWd2C2h+geHueCOxzh76/e54I7HDpsSWWmNvtjrE1MN/xIVJiU0YoqoSFJpzX8eqPfgpUo7acvtOC287uKOthk7X8sJG+9PQeg4f1dHG+OTU6FbFIXZPmEOjme54I7H2NjXy+bzT657aKdRB4GJzEcK/5grnU0zNDrOn353L0DF4KoU8LPNie8fHGa0iuAv1ZaC69YZT/77gRkzeQrW2LGc9utdhwXwf3/HiYyMHOK8L+8qO4RUqH/z+Sdz30dW1FxbNQs8kSRR+Mfc1of2HbZ2PTGVY+tD+yqGVqWAr7TjtPDces6vPZmj4snZdj33KtesOaVs3alUquLrRzloSweBicyk8I+5ckMvsw3JVAr42XacVjveX8vfreZ1D1axtVHpNSoN68y2wBNJGu3wPUKVO7ipEIqVdpxGOTCqp7O94t+e7bnVvH6Y2c7tU29NIkcqhX/MLW7P1NReUCng1y3vYfP5J7O0s50UsLSznc3nnzy9lryxr5cF6cOHYFIQ2l7Qlso/t95ZOWHPq/Y1ZrtGgGYKicykYZ+Y+5PzTuKGfmeyaNi/LZVvr2S2g54qzYkvtIedr6fwmkOj4zNm9XRkUrQvyLDlO37YiduqnVlTWvPiWc7zU2y2YR0dBCYyk8I/5loVWtUsHAoKQy6FBcXQ6Djf/tHPZ2xNzMXfraSac/voIDCRNyj854F6Qmu2qY2zzXkvfXzlbxxTdk2+3JDLdd/x6a2H4q2Exe0Z3vW2JXzzyaHDjgdIp+B3T13KNWtOCX1fn/veXu59amj6mICjFqR5fWKKcoNRtQ7rFJ/PKOx4hcLxCEuLPpPis5Iubs+QSqU4MDY5o2+hjuKtqcLW0sGxyURsieg4i3g5ok/pXPxDLv0hzuWXbrbTrfYPDvP5f3p2eg57IVTKHQwlIuGq/c2kU7DsmA5+9uoYU7nwlYqwFZwHf/JSxdOVNCI/Kile2Zltxaiccqd0PmLDv9KJyTra0jUNSZSer76g8EUoHKRU6Bt2JkwRab3CwqOro43Xxidn7EurVaMXBJ/73t7QgyV/77TaFgCxO5+/maWBbcBpwDjwB+7+7Fy9fqUTk9VycE/Y+eoLCkMpRy9qZ9Wy7lnPhCkirVX4FVdz6pLZNPoo8XufOjz4C+21rv2HaeVUz98BOtz9HcA1wNa5fPHZDt6p9uCecuerLxibnGLrg3un+yr4RZKjeDrxXCsXO3N1qvRWhv85wHcB3P0HhGyWRDEXBxRBdQuJFw+MVd1XRI4sjfrdlzukpsKhNjVp5WyfxcCBovtZM2tz99DtsUwmRXf3oqpf/BNrjU/949OMTYSM+S9I84m1VtXrvaWrgxeCcC/bp7uD7u5FVfUVkSPLW7o6asqmam34zePZsfvfQtvn4u+1MvwPAp1F99Plgh8gm83VdAHjVcu62fyuk8vO9lm1rLuq17ts5bKyY/6Q33l85ZpTGBk5xGUrl2nMX2SeWJBOcdSC9PRBhEctSPHTX9S28tbRluaylcsacgH4K/pOZHx84rDZPlf0nVjT31uypDO0vZXhvwu4APh7M/st4F/n+g/MxUE9YUe7FhQWJO897a2MjByaMe9ds31kPqp2KmVHJsV4Njfd96i2FJ88/40ztvYPDvPZnXt5PZhOkwIuOm3pjFN6txe9Ruk0xuJpmJ0hx04c1Zaafu2CE9/UwbFHL+SH/3aw7PsKm/JdPFV7tqmVzT5W4Zo1p3DNmlNmnU5ej5ZN9Sya7XMq+f/Nh9z9J+X61zPPv1ka8Y+pRqUv4gV3PKYFUIij2lIsbMscduBZQQqmQ6ktBRNFHU58UwevT+SmTz3xq8nsdAAVTn9R6UC50qCYiznc0LrvX7VUX3RRakzcPP9miuOXJ2zaafHxDZWCaa7mF9dTG8zdqSzmai0tjv/fYqovmrjXB40Jf53e4QgV5cRuhYCfi7XSamp7S1cHl61cNqO2ufo7On2ASDit+c+BuK85qL5oVF80qi+6Rqz563z+IiIJpPAXEUkghb+ISAIp/EVEEkjhLyKSQPNmtg/wEvCzVhchIjLPLAOWlDbOp/AXEZE5omEfEZEEUviLiCSQwl9EJIEU/iIiCaTwFxFJIIW/iEgC6ZTONTKzBcBdQC/QDtwI/D/gPuCZoNtfufv/bkmBgJnt4Y3rI/8U+Gvgi8AksNPdP9PC2j4IfDC42wGcDrwP+AugcMHSLe7+cAtqWwHc7O6rzewkYDv56708DWxy9ykz2wKsJ/9ZXu7uu1tU3+nAl4AsMA58wN2HzexWYCUwGjztQnc/EP6KDa3vDEJ+EzH6/P4XsDR4qBf4gbtvMLNvAW8GJoDX3X1dk2oLy5Uf08DvoMK/dhcDr7j7+83szcAe4AbgFnff2trSwMw6ANx9dVHbE8DvAc8B3zazM9z9/7aiPnffTv4LjZndRv4LfwZwlbvf04qaglquAt4PvBY03QJc6+7/Yma3Axea2c+Ac4EVwPHAPcBvtqi+LwIfdfcnzOxS4Grgj8l/lmvd/eVm1FWhvjMo+U0EC4RYfH7uviFoPwb4Z+CKoOtJwNvdvdkHQIXlyhM08DuoYZ/a/QPw6aL7k8CZwHoz+76ZfdXMwq+Y3BynAYvMbKeZPWRmq4B2d98XfKEfAM5rYX0AmNlZ5H9kd5D//C4xswEz22pmrVgp2QdcVHT/TKCw9dEPrAHOIb/llHP354E2MzvsyMkm1bfB3Z8IbrcBY8GlUU8G7jCzXWZ2SZNqC6sv7DcRp8+v4DPAl9z9RTPrAbqB+8zsETN7T5Nqg/K50rDvoMK/Ru7+S3cfDb7MdwPXAruBT7j7KvJr11taWOIh4PPAWuAy4H8GbQWjQFcL6iq1mfwPD+BB4KPAKuDXyNfdVMFWx0RRU6po7a/wmS3mjeG04vam1+fuLwKY2TuBPwK+ABxNfijoYuC3gY1mdmor6iP8NxGbzw/AzI4jvyK0PWhaCGwFfof8guILQZ9m1BeWKw39Dir862Bmx5PfVPy6u+8A7nX3x4OH7wX+S8uKg73A3wZrBnvJf1HeVPR4JzDSksoCZtYNvM3d/zlousvdnwu+6P9Iaz+/gqmi24XP7GBwu7S9Jczs94HbgfXu/hL5hfwX3f2Qu48CD5HfEmyFsN9ErD4/4L8CO9w9G9wfAm5390l3/zn5oRdrVjEhudLQ76DCv0bBpuFO4Gp3vytofsDMzg5unwc8Hvrk5riE/NoLZvZWYBHwmpn9RzNLkd8iGGhhfZBfw/8eQFDTU2b2H4LHWv35Fewxs9XB7XXkP7NdwFozS5vZCUC62WPrBWZ2Mfk1/tXu/lzQfArwiJllgh2I5wAt2bdD+G8iNp9fYA354ZTi+38PYGa/BvxnYLAZhZTJlYZ+B7XDt3abgWOAT5tZYYzuj4G/NLNfkV97+EirigO+Cmw3s0fIzxK4hPwaxDeADPnxwsdaWB/k16aeA3D3nJn9AfBNM3ud/AyHO1tZXOBK4E4zW0g+AO5296yZDQCPkl9x2tSKwswsA9wKPE/+cwN42N23mNk3gB+QH+L4G3f/UStqBP4Q+HLxb8LdD8bh8ysy/T0EcPd+M1trZj8g/5vZ3MSFU1iufBy4tVHfQZ3VU0QkgTTsIyKSQAp/EZEEUviLiCSQwl9EJIEU/iIiCaTwFxFJIIW/iEgC/X+++ECybwa3NgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(data.weight, data.ap_hi)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Визуализируем взаимосвязь между  weight и ap_lo {Diastolic blood pressure}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(data.weight, data.ap_lo)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Визуализируем зависимость между ap_hi {Systolic blood pressure} и ap_lo {Diastolic blood pressure}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(data.ap_hi, data.ap_lo)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# С использованием t-test статистики проверим взаимосвязи между несколькими переменными"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как тестировать две переменные, как посчитать степени свободы: https://towardsdatascience.com/inferential-statistics-series-t-test-using-numpy-2718f8f9bf2f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Метод 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=-2079.746249421458, pvalue=0.0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.ttest_ind(data.weight, data.age)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p-value < 0.05, поэтому можно сказать что имеется статистическое различие между атрибутами. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Метод 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Библиотека researchpy: pip install researchpy"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "summary_cont() - \n",
    "Returns a nice data table as a Pandas DataFrame that includes the variable name, total number of non-missing observations, standard deviation, standard error, and the 95% confidence interval."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "https://researchpy.readthedocs.io/en/latest/summary_cont_documentation.html#summary-cont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N</th>\n",
       "      <th>Mean</th>\n",
       "      <th>SD</th>\n",
       "      <th>SE</th>\n",
       "      <th>95% Conf.</th>\n",
       "      <th>Interval</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cardio</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35021</td>\n",
       "      <td>1.3457</td>\n",
       "      <td>0.4756</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>1.3407</td>\n",
       "      <td>1.3507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34979</td>\n",
       "      <td>1.3534</td>\n",
       "      <td>0.4780</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>1.3484</td>\n",
       "      <td>1.3585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            N    Mean      SD      SE  95% Conf.  Interval\n",
       "cardio                                                    \n",
       "0       35021  1.3457  0.4756  0.0025     1.3407    1.3507\n",
       "1       34979  1.3534  0.4780  0.0026     1.3484    1.3585"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import researchpy as rp\n",
    "# Showing descriptive statistics from researchpy.summary_cont()\n",
    "rp.summary_cont(data.groupby('cardio')['gender'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N - количество элементов\n",
    "Mean - среднее значение\n",
    "SD - стандартное отклонение\n",
    "SE - стандартная ошибка (https://ru.wikipedia.org/wiki/Стандартная_ошибка)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция для подсчета t-test: https://researchpy.readthedocs.io/en/latest/ttest_documentation.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable</th>\n",
       "      <th>N</th>\n",
       "      <th>Mean</th>\n",
       "      <th>SD</th>\n",
       "      <th>SE</th>\n",
       "      <th>95% Conf.</th>\n",
       "      <th>Interval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cardio</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>0.499700</td>\n",
       "      <td>0.500003</td>\n",
       "      <td>0.001890</td>\n",
       "      <td>0.495996</td>\n",
       "      <td>0.503404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>weight</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>74.205690</td>\n",
       "      <td>14.395757</td>\n",
       "      <td>0.054411</td>\n",
       "      <td>74.099045</td>\n",
       "      <td>74.312335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>combined</td>\n",
       "      <td>140000.0</td>\n",
       "      <td>37.352695</td>\n",
       "      <td>38.234750</td>\n",
       "      <td>0.102187</td>\n",
       "      <td>37.152411</td>\n",
       "      <td>37.552979</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Variable         N       Mean         SD        SE  95% Conf.   Interval\n",
       "0    cardio   70000.0   0.499700   0.500003  0.001890   0.495996   0.503404\n",
       "1    weight   70000.0  74.205690  14.395757  0.054411  74.099045  74.312335\n",
       "2  combined  140000.0  37.352695  38.234750  0.102187  37.152411  37.552979"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "descriptives, results = rp.ttest(data.cardio, data.weight)\n",
    "\n",
    "descriptives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Independent t-test</th>\n",
       "      <th>results</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Difference (cardio - weight) =</td>\n",
       "      <td>-73.7060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Degrees of freedom =</td>\n",
       "      <td>139998.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>t =</td>\n",
       "      <td>-1353.8031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Two side test p value =</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Difference &lt; 0 p value =</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Difference &gt; 0 p value =</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Cohen's d =</td>\n",
       "      <td>-7.2364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Hedge's g =</td>\n",
       "      <td>-7.2363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Glass's delta =</td>\n",
       "      <td>-147.4110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>r =</td>\n",
       "      <td>0.9639</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Independent t-test      results\n",
       "0  Difference (cardio - weight) =      -73.7060\n",
       "1            Degrees of freedom =   139998.0000\n",
       "2                             t =    -1353.8031\n",
       "3         Two side test p value =        0.0000\n",
       "4        Difference < 0 p value =        0.0000\n",
       "5        Difference > 0 p value =        1.0000\n",
       "6                     Cohen's d =       -7.2364\n",
       "7                     Hedge's g =       -7.2363\n",
       "8                 Glass's delta =     -147.4110\n",
       "9                             r =        0.9639"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "two-side p-value < 0.05, поэтому можно сказать что имеется статистическое различие между атрибутами. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Difference (cardio - weight) = разница между средними двух атрибутов\n",
    "Degrees of freedom = степени свободы для двух атрибутов\n",
    "t = t-value\n",
    "Two side test p value =\tpvalue\n",
    "Difference < 0 p value = pvalue для гипотезы, что разницы между двумя переменными отсутствует\n",
    "Difference > 0 p value = pvalue для гипотезы, что разница между двумя переменными есть\n",
    "Cohen's d = https://researchpy.readthedocs.io/en/latest/ttest_documentation.html#cohen-s-dz-within-subject-design\n",
    "Hedge's g = https://researchpy.readthedocs.io/en/latest/ttest_documentation.html#hedges-s-gs-between-subjects-design\n",
    "Glass's delta = https://researchpy.readthedocs.io/en/latest/ttest_documentation.html#glass-s-delta-between-or-within-subjects-design\n",
    "r = коэффициент корреляции Пирсона"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>18393</td>\n",
       "      <td>2</td>\n",
       "      <td>168</td>\n",
       "      <td>62.0</td>\n",
       "      <td>110</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20228</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>85.0</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>18857</td>\n",
       "      <td>1</td>\n",
       "      <td>165</td>\n",
       "      <td>64.0</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>17623</td>\n",
       "      <td>2</td>\n",
       "      <td>169</td>\n",
       "      <td>82.0</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>17474</td>\n",
       "      <td>1</td>\n",
       "      <td>156</td>\n",
       "      <td>56.0</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id    age  gender  height  weight  ap_hi  ap_lo  cholesterol  gluc  smoke  \\\n",
       "0   0  18393       2     168    62.0    110     80            1     1      0   \n",
       "1   1  20228       1     156    85.0    140     90            3     1      0   \n",
       "2   2  18857       1     165    64.0    130     70            3     1      0   \n",
       "3   3  17623       2     169    82.0    150    100            1     1      0   \n",
       "4   4  17474       1     156    56.0    100     60            1     1      0   \n",
       "\n",
       "   alco  active  cardio  \n",
       "0     0       1       0  \n",
       "1     0       1       1  \n",
       "2     0       0       1  \n",
       "3     0       1       1  \n",
       "4     0       0       0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Протестируем гипотезу, что женщины болеют чаще чем мужчины"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "female = data[data['gender']==1].cardio\n",
    "male = data[data['gender']==2].cardio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptives, results = rp.ttest(female, male)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напечатаем результат:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Variable        N      Mean        SD        SE  95% Conf.  Interval\n",
      "0    cardio  45530.0  0.496727  0.499995  0.002343   0.492135  0.501320\n",
      "1    cardio  24470.0  0.505231  0.499983  0.003196   0.498966  0.511496\n",
      "2  combined  70000.0  0.499700  0.500003  0.001890   0.495996  0.503404\n",
      "_______________________________________\n",
      "                Independent t-test     results\n",
      "0  Difference (cardio - cardio) =      -0.0085\n",
      "1            Degrees of freedom =   69998.0000\n",
      "2                             t =      -2.1456\n",
      "3         Two side test p value =       0.0319\n",
      "4        Difference < 0 p value =       0.0160\n",
      "5        Difference > 0 p value =       0.9840\n",
      "6                     Cohen's d =      -0.0170\n",
      "7                     Hedge's g =      -0.0170\n",
      "8                 Glass's delta =      -0.0170\n",
      "9                             r =       0.0081\n"
     ]
    }
   ],
   "source": [
    "print(descriptives)\n",
    "print('_______________________________________')\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно заметить, что есть разница между женщинами и мужчинами (pvalue<0.05). Возможно это связано с тем, что женщин в выборке в 2 раза больше чем мужчин."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проверим гипотезу о том, что люди с показателем cholesterol = 2 болеют чаще"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "chol_2 = data[data['cholesterol']==2].cardio\n",
    "chol_all = data[data['cholesterol']!=2].cardio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Variable        N      Mean        SD        SE  95% Conf.  Interval\n",
      "0    cardio   9549.0  0.602157  0.489478  0.005009   0.592339  0.611976\n",
      "1    cardio  60451.0  0.483516  0.499732  0.002033   0.479532  0.487499\n",
      "2  combined  70000.0  0.499700  0.500003  0.001890   0.495996  0.503404\n",
      "_____________________________\n",
      "                Independent t-test     results\n",
      "0  Difference (cardio - cardio) =       0.1186\n",
      "1            Degrees of freedom =   69998.0000\n",
      "2                             t =      21.6191\n",
      "3         Two side test p value =       0.0000\n",
      "4        Difference < 0 p value =       1.0000\n",
      "5        Difference > 0 p value =       0.0000\n",
      "6                     Cohen's d =       0.2381\n",
      "7                     Hedge's g =       0.2381\n",
      "8                 Glass's delta =       0.2424\n",
      "9                             r =       0.0814\n"
     ]
    }
   ],
   "source": [
    "descriptives, results = rp.ttest(chol_2, chol_all)\n",
    "print(descriptives)\n",
    "print('_____________________________')\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p value = 0.0000, то отличие людей с показателем chol = 2 значительное"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=21.619123191535245, pvalue=2.5898307558677926e-103)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.ttest_ind(chol_2, chol_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Значит, люди с показателем chol=2 болеют чаще, чем остальные (среднее значение выборки больше чем остальных)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проверим гипотезу о том, что люди, которые курят, болеют чаще сердечной болезнью"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Variable        N      Mean        SD        SE  95% Conf.  Interval\n",
      "0    cardio   6169.0  0.474793  0.499405  0.006358   0.462329  0.487258\n",
      "1    cardio  63831.0  0.502107  0.499999  0.001979   0.498228  0.505986\n",
      "2  combined  70000.0  0.499700  0.500003  0.001890   0.495996  0.503404\n",
      "_____________________________\n",
      "                Independent t-test     results\n",
      "0  Difference (cardio - cardio) =      -0.0273\n",
      "1            Degrees of freedom =   69998.0000\n",
      "2                             t =      -4.0976\n",
      "3         Two side test p value =       0.0000\n",
      "4        Difference < 0 p value =       0.0000\n",
      "5        Difference > 0 p value =       1.0000\n",
      "6                     Cohen's d =      -0.0546\n",
      "7                     Hedge's g =      -0.0546\n",
      "8                 Glass's delta =      -0.0547\n",
      "9                             r =       0.0155\n"
     ]
    }
   ],
   "source": [
    "smoke = data[data['smoke']==1].cardio\n",
    "no_smoke = data[data['smoke']==0].cardio\n",
    "descriptives, results = rp.ttest(smoke, no_smoke)\n",
    "print(descriptives)\n",
    "print('_____________________________')\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Difference > 0 p value = 1.0000, значит, различие в двух выборках значительное.  Среднее значение по атрибуту cardio у курящих 0.47, среднее значение среди некурящих 0.50, скорее связано с тем, что выборки имеют разное количество элементов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=-4.097626290112295, pvalue=4.1787798766011306e-05)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.ttest_ind(smoke, no_smoke)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задача:  создать модель, предсказывающую наличие болезни по параметрам, заданным в таблице"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>ap_hi</th>\n",
       "      <th>ap_lo</th>\n",
       "      <th>cholesterol</th>\n",
       "      <th>gluc</th>\n",
       "      <th>smoke</th>\n",
       "      <th>alco</th>\n",
       "      <th>active</th>\n",
       "      <th>cardio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>69995</th>\n",
       "      <td>99993</td>\n",
       "      <td>19240</td>\n",
       "      <td>2</td>\n",
       "      <td>168</td>\n",
       "      <td>76.0</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69996</th>\n",
       "      <td>99995</td>\n",
       "      <td>22601</td>\n",
       "      <td>1</td>\n",
       "      <td>158</td>\n",
       "      <td>126.0</td>\n",
       "      <td>140</td>\n",
       "      <td>90</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69997</th>\n",
       "      <td>99996</td>\n",
       "      <td>19066</td>\n",
       "      <td>2</td>\n",
       "      <td>183</td>\n",
       "      <td>105.0</td>\n",
       "      <td>180</td>\n",
       "      <td>90</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69998</th>\n",
       "      <td>99998</td>\n",
       "      <td>22431</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>72.0</td>\n",
       "      <td>135</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69999</th>\n",
       "      <td>99999</td>\n",
       "      <td>20540</td>\n",
       "      <td>1</td>\n",
       "      <td>170</td>\n",
       "      <td>72.0</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id    age  gender  height  weight  ap_hi  ap_lo  cholesterol  gluc  \\\n",
       "69995  99993  19240       2     168    76.0    120     80            1     1   \n",
       "69996  99995  22601       1     158   126.0    140     90            2     2   \n",
       "69997  99996  19066       2     183   105.0    180     90            3     1   \n",
       "69998  99998  22431       1     163    72.0    135     80            1     2   \n",
       "69999  99999  20540       1     170    72.0    120     80            2     1   \n",
       "\n",
       "       smoke  alco  active  cardio  \n",
       "69995      1     0       1       0  \n",
       "69996      0     0       1       1  \n",
       "69997      0     1       0       1  \n",
       "69998      0     0       0       1  \n",
       "69999      0     0       1       0  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = data.drop(['id', 'cardio'], axis=1), data.cardio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.588076</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.579487</td>\n",
       "      <td>0.273684</td>\n",
       "      <td>0.016079</td>\n",
       "      <td>0.013550</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.730159</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.517949</td>\n",
       "      <td>0.394737</td>\n",
       "      <td>0.017934</td>\n",
       "      <td>0.014453</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.624003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.564103</td>\n",
       "      <td>0.284211</td>\n",
       "      <td>0.017316</td>\n",
       "      <td>0.012647</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.528455</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.584615</td>\n",
       "      <td>0.378947</td>\n",
       "      <td>0.018553</td>\n",
       "      <td>0.015357</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.516918</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.517949</td>\n",
       "      <td>0.242105</td>\n",
       "      <td>0.015461</td>\n",
       "      <td>0.011743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0    1         2         3         4         5    6    7    8    9  \\\n",
       "0  0.588076  1.0  0.579487  0.273684  0.016079  0.013550  0.0  0.0  0.0  0.0   \n",
       "1  0.730159  0.0  0.517949  0.394737  0.017934  0.014453  1.0  0.0  0.0  0.0   \n",
       "2  0.624003  0.0  0.564103  0.284211  0.017316  0.012647  1.0  0.0  0.0  0.0   \n",
       "3  0.528455  1.0  0.584615  0.378947  0.018553  0.015357  0.0  0.0  0.0  0.0   \n",
       "4  0.516918  0.0  0.517949  0.242105  0.015461  0.011743  0.0  0.0  0.0  0.0   \n",
       "\n",
       "    10  \n",
       "0  1.0  \n",
       "1  1.0  \n",
       "2  0.0  \n",
       "3  1.0  \n",
       "4  0.0  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "min_max_scaler = preprocessing.MinMaxScaler(feature_range=(0,1))\n",
    "\n",
    "np_scaled = min_max_scaler.fit_transform(x)\n",
    "df_norm = pd.DataFrame(np_scaled)\n",
    "df_norm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(df_norm,y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используем модель **Наивный Байес**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the accuracy of our model: 0.5932857142857143\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb = GaussianNB()\n",
    "nb.fit(x_train,y_train)\n",
    "print(\"the accuracy of our model: {}\".format(nb.score(x_test,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.87      0.68      6988\n",
      "           1       0.71      0.32      0.44      7012\n",
      "\n",
      "    accuracy                           0.59     14000\n",
      "   macro avg       0.64      0.59      0.56     14000\n",
      "weighted avg       0.64      0.59      0.56     14000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, nb.predict(x_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "our accuracy is: 0.6545714285714286\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(max_iter = 200)\n",
    "lr.fit(x_train,y_train)\n",
    "print(\"our accuracy is: {}\".format(lr.score(x_test,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.68      0.66      6988\n",
      "           1       0.66      0.63      0.65      7012\n",
      "\n",
      "    accuracy                           0.65     14000\n",
      "   macro avg       0.66      0.65      0.65     14000\n",
      "weighted avg       0.66      0.65      0.65     14000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, lr.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Очень низкий recall - это может быть связано с **несбалансированностью классов**. Сравним модель **Наивного Байеса** с моделью **Random Forest**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=None, max_features='auto',\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# создаем модель деревья решений\n",
    "# выбираем 100 деревьев в качестве параметра\n",
    "model=RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "# обучаем модель\n",
    "model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель Random Forest дает лучше результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.73      0.72      6988\n",
      "           1       0.72      0.70      0.71      7012\n",
      "\n",
      "    accuracy                           0.71     14000\n",
      "   macro avg       0.71      0.71      0.71     14000\n",
      "weighted avg       0.71      0.71      0.71     14000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_pred = model.predict(x_test)\n",
    "\n",
    "print(classification_report(y_test, model_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Определение СПАМа в тексте"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XvItYzkj6nUK"
   },
   "source": [
    "Датасет для определения СПАМа в тексте.  https://www.kaggle.com/team-ai/spam-text-message-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "Df9gsOk36YpQ",
    "outputId": "ddc3a729-c218-494e-9e0a-8e30856a163d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Category                                            Message\n",
       "5567     spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568      ham               Will ü b going to esplanade fr home?\n",
       "5569      ham  Pity, * was in mood for that. So...any other s...\n",
       "5570      ham  The guy did some bitching but I acted like i'd...\n",
       "5571      ham                         Rofl. Its true to its name"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url='http://yustiks.ru/dataset/SPAM_text.csv'\n",
    "data=pd.read_csv(url) \n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "jvKJuvWXaNqw",
    "outputId": "76fcd9a3-c1a0-4f6b-e98a-76c12f2243e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\n"
     ]
    }
   ],
   "source": [
    "print(data.loc[2, 'Message'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим новый атрибут Category, где будем указывать, что если данный текст является СПАМом, то 1, если не является, то 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DiBSfYAu7E3J"
   },
   "outputs": [],
   "source": [
    "data[\"Category\"] = [1 if each == \"spam\" else 0 for each in data[\"Category\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "DxJF-FT57GgK",
    "outputId": "3e1a5e9d-4442-4880-e766-7ced24846726"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Category                                            Message\n",
       "0         0  Go until jurong point, crazy.. Available only ...\n",
       "1         0                      Ok lar... Joking wif u oni...\n",
       "2         1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3         0  U dun say so early hor... U c already then say...\n",
       "4         0  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a9Vu6XzsBfWw"
   },
   "source": [
    "Как на основе текста предсказать, что он является СПАМом? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bwcux5EgBqJN"
   },
   "source": [
    "# Словарь BAG-of-words. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gAuXKIzSB-82"
   },
   "source": [
    "Создаем слова. На основе слов пишем для каждого текста словарь, где каждое слово - это ключ, а значение ключа - это сколько раз встречается данное слова в данном тексте."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zyjsN0ZqPPgn"
   },
   "source": [
    "Как пример: рассмотрим 1 строку из датасета.\n",
    "\n",
    "\n",
    "\n",
    "*   Удалим все символы, не являющимися латинскими буквами\n",
    "*   Заглавные буквы меняем на строчные\n",
    "*   Разделим текст на слова\n",
    "*   В каждом слове выделяем корень слова\n",
    "*   Создаем список всех слов\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "rq4UlSZkNH-E",
    "outputId": "2706c926-e86a-4b89-ad4f-b616c6782465"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "nlp_data = str(data.loc[2, 'Message'])\n",
    "print(nlp_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0E_4QMsONv3v"
   },
   "source": [
    "Удаление всех не латинских букв:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "yRM_Ykz3NJvK",
    "outputId": "8a8de0e0-e526-4e18-ff00-14cedfac6e45"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Free entry in   a wkly comp to win FA Cup final tkts   st May       Text FA to       to receive entry question std txt rate T C s apply            over   s\n"
     ]
    }
   ],
   "source": [
    "nlp_data = re.sub(\"[^a-zA-Z]\",\" \", nlp_data)\n",
    "print(nlp_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y_TIDOgsN-Y_"
   },
   "source": [
    "Во всех словах заглавные буквы меняем на строчные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "qzy8kpblN5aE",
    "outputId": "345d4441-b118-4223-b7d4-94e554191a64"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "free entry in   a wkly comp to win fa cup final tkts   st may       text fa to       to receive entry question std txt rate t c s apply            over   s\n"
     ]
    }
   ],
   "source": [
    "nlp_data = nlp_data.lower()\n",
    "print(nlp_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5ibxAPXnOgvj"
   },
   "source": [
    "Переводим текст в отдельные слова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "XOhX6nvMOPJD",
    "outputId": "dfbec726-4992-4077-f1d7-e5c92168ccab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['free', 'entry', 'in', 'a', 'wkly', 'comp', 'to', 'win', 'fa', 'cup', 'final', 'tkts', 'st', 'may', 'text', 'fa', 'to', 'to', 'receive', 'entry', 'question', 'std', 'txt', 'rate', 't', 'c', 's', 'apply', 'over', 's']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/yustinaivanova/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk as nlp # библиотека nltk -> pip install nltk \n",
    "nlp.download('punkt')\n",
    "nlp_data = nlp.word_tokenize(nlp_data)\n",
    "print(nlp_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5dpudpmrO_Tp"
   },
   "source": [
    "Ищем корень каждого слова"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "hbPUYfsTOo9o",
    "outputId": "31f936e5-61e1-4e48-8d43-842b52261f4a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/yustinaivanova/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['free', 'entry', 'in', 'a', 'wkly', 'comp', 'to', 'win', 'fa', 'cup', 'final', 'tkts', 'st', 'may', 'text', 'fa', 'to', 'to', 'receive', 'entry', 'question', 'std', 'txt', 'rate', 't', 'c', 's', 'apply', 'over', 's']\n"
     ]
    }
   ],
   "source": [
    "nlp.download('wordnet')\n",
    "lemma = nlp.WordNetLemmatizer()\n",
    "nlp_data = [lemma.lemmatize(word) for word in nlp_data]\n",
    "print(nlp_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "40keBPrTCLqB"
   },
   "source": [
    "Добавляем все найденные слова в список"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3O1MxC11PJ70"
   },
   "outputs": [],
   "source": [
    "nlp_data = \" \".join(nlp_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aWpIjfZiQk8u"
   },
   "outputs": [],
   "source": [
    "description_list = []\n",
    "for description in data[\"Message\"]:\n",
    "    description = re.sub(\"[^a-zA-Z]\",\" \",description)\n",
    "    description = description.lower()\n",
    "    description = nlp.word_tokenize(description)\n",
    "    lemma = nlp.WordNetLemmatizer()\n",
    "    description = [ lemma.lemmatize(word) for word in description]\n",
    "    description = \" \".join(description)\n",
    "    description_list.append(description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сколько всего получилось слов в словаре мешка слов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Yb7nm-_YcDQd",
    "outputId": "3fe4bd78-1d3c-498e-ab4c-7e18bd161733"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5572"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(description_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "xloAtHs2dw3U",
    "outputId": "a459b93e-4ccf-401c-9afc-09c02c66a941"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "go until jurong point crazy available only in bugis n great world la e buffet cine there got amore wat\n"
     ]
    }
   ],
   "source": [
    "print(description_list[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xZBGlFp0Q2NW"
   },
   "source": [
    "Создаем bag-of-words, для этого выбираем 3000 максимально встречаемых слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "uH0OST_KQ4gj",
    "outputId": "45c24f21-fb14-4016-b4fc-1dc0dc8cd90f",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Самые часто встречаемые 3000 слов: ['aah', 'aathi', 'abi', 'ability', 'abiola', 'abj', 'able', 'absolutly', 'abt', 'abta', 'aburo', 'ac', 'academic', 'acc', 'accept', 'access', 'accident', 'accidentally', 'accordingly', 'account', 'ache', 'acl', 'aco', 'acted', 'acting', 'action', 'activate', 'active', 'activity', 'actor', 'actual', 'actually', 'ad', 'adam', 'add', 'addamsfa', 'added', 'addicted', 'addie', 'address', 'admin', 'administrator', 'admirer', 'admit', 'adore', 'adoring', 'adult', 'advance', 'adventure', 'advice', 'advise', 'ae', 'aeronautics', 'aeroplane', 'affair', 'affection', 'afraid', 'aft', 'afternoon', 'aftr', 'ag', 'agalla', 'age', 'agent', 'ago', 'agree', 'ah', 'aha', 'ahead', 'ahmad', 'aid', 'aight', 'ain', 'aint', 'air', 'airport', 'airtel', 'aiya', 'aiyah', 'aiyar', 'aiyo', 'aj', 'aka', 'al', 'alaipayuthe', 'album', 'alcohol', 'alert', 'alex', 'alfie', 'algarve', 'ali', 'alive', 'allah', 'allow', 'allowed', 'alright', 'alrite', 'alwys', 'amazing', 'american', 'amp', 'amt', 'amused', 'amy', 'andros', 'angry', 'animation', 'anna', 'annie', 'anniversary', 'announcement', 'annoying', 'anot', 'ansr', 'answer', 'answered', 'answering', 'anthony', 'anti', 'anybody', 'anymore', 'anythin', 'anytime', 'anyways', 'aom', 'apart', 'apartment', 'apo', 'apologise', 'app', 'apparently', 'apple', 'applebees', 'application', 'apply', 'appointment', 'appreciate', 'appreciated', 'approx', 'apps', 'appt', 'april', 'aproach', 'ar', 'arcade', 'ard', 'area', 'aren', 'arent', 'argh', 'argue', 'argument', 'arm', 'armand', 'arng', 'arrange', 'arrested', 'arrive', 'arsenal', 'art', 'arun', 'asap', 'ashley', 'ask', 'askd', 'asked', 'askin', 'asking', 'asks', 'asleep', 'asp', 'assume', 'ate', 'atlanta', 'atlast', 'atm', 'attached', 'attempt', 'attend', 'auction', 'audition', 'audrey', 'august', 'aunt', 'aunty', 'auto', 'av', 'available', 'avatar', 'ave', 'avent', 'avoid', 'avoiding', 'await', 'awaiting', 'awake', 'award', 'awarded', 'away', 'awesome', 'aww', 'ayn', 'ba', 'babe', 'baby', 'bad', 'bag', 'bahamas', 'bak', 'balance', 'ball', 'bang', 'bank', 'bar', 'barely', 'base', 'basic', 'basically', 'bat', 'batch', 'bath', 'bathe', 'bathing', 'battery', 'battle', 'bay', 'bb', 'bbd', 'bc', 'bck', 'bcm', 'bcoz', 'bcums', 'bday', 'bear', 'beautiful', 'beauty', 'bec', 'becoz', 'bed', 'bedrm', 'bedroom', 'beer', 'befor', 'beg', 'begging', 'begin', 'behave', 'bein', 'believe', 'belive', 'bell', 'belly', 'belovd', 'beloved', 'ben', 'beneath', 'beneficiary', 'benefit', 'best', 'bet', 'better', 'beware', 'bf', 'bhaji', 'bid', 'big', 'bigger', 'biggest', 'billed', 'billion', 'bin', 'biola', 'bird', 'birla', 'birth', 'birthdate', 'birthday', 'bishan', 'bit', 'bitch', 'bite', 'biz', 'bk', 'black', 'blackberry', 'blah', 'blake', 'blame', 'blank', 'blanket', 'bleh', 'bless', 'blessed', 'blessing', 'blind', 'block', 'bloke', 'blonde', 'bloo', 'blood', 'bloody', 'bloomberg', 'blow', 'blu', 'blue', 'bluetooth', 'bluff', 'blur', 'bmw', 'boat', 'body', 'bold', 'bone', 'bonus', 'boo', 'book', 'booked', 'booking', 'boost', 'booty', 'bootydelious', 'bored', 'borin', 'boring', 'born', 'borrow', 'bos', 'boston', 'bother', 'bottle', 'bought', 'bout', 'bowl', 'box', 'boy', 'boye', 'boyfriend', 'boytoy', 'bp', 'brah', 'brain', 'brand', 'brandy', 'bray', 'bread', 'break', 'breath', 'breathe', 'brief', 'bright', 'brilliant', 'bring', 'bringing', 'brings', 'bristol', 'british', 'britney', 'bro', 'broad', 'broke', 'broken', 'bros', 'brothas', 'brother', 'brought', 'brownie', 'bruce', 'bruv', 'bslvyl', 'bstfrnd', 'bt', 'btw', 'buck', 'bud', 'buddy', 'budget', 'buff', 'buffet', 'bugis', 'build', 'building', 'bulb', 'bun', 'burger', 'burn', 'burning', 'bus', 'business', 'busy', 'butt', 'buy', 'buyer', 'buying', 'buzy', 'buzz', 'bx', 'bye', 'cabin', 'cafe', 'cake', 'cal', 'calculation', 'cali', 'calicut', 'california', 'callback', 'callcost', 'calld', 'called', 'caller', 'callertune', 'callfreefone', 'callin', 'calling', 'calm', 'cam', 'camcorder', 'came', 'camera', 'campus', 'canada', 'canal', 'canary', 'cancel', 'cancelled', 'cancer', 'cann', 'capital', 'cappuccino', 'captain', 'car', 'card', 'cardiff', 'care', 'cared', 'career', 'careful', 'carefully', 'caring', 'carlos', 'caroline', 'carry', 'cartoon', 'case', 'cash', 'cashbin', 'cashto', 'castor', 'cat', 'catch', 'catching', 'caught', 'cause', 'causing', 'cbe', 'cc', 'cd', 'cdgt', 'celeb', 'celebrate', 'celebration', 'cell', 'center', 'centre', 'certainly', 'ch', 'cha', 'chain', 'challenge', 'chance', 'change', 'changed', 'channel', 'character', 'charge', 'charged', 'charity', 'charles', 'chart', 'chase', 'chasing', 'chat', 'chatting', 'cheap', 'cheaper', 'cheat', 'cheating', 'chechi', 'check', 'checked', 'checking', 'cheer', 'chennai', 'chicken', 'chikku', 'child', 'childish', 'chill', 'chillin', 'china', 'chinese', 'choice', 'choose', 'chosen', 'christmas', 'church', 'cine', 'cinema', 'citizen', 'city', 'claim', 'claire', 'class', 'clean', 'cleaning', 'clear', 'cleared', 'click', 'clock', 'clos', 'close', 'closed', 'closer', 'club', 'cm', 'cn', 'cock', 'code', 'coffee', 'coin', 'cold', 'colleague', 'collect', 'collected', 'collecting', 'collection', 'college', 'colour', 'com', 'come', 'comedy', 'comin', 'coming', 'common', 'community', 'comp', 'company', 'competition', 'complete', 'completely', 'complimentary', 'computer', 'comuk', 'concentrate', 'concert', 'condition', 'confidence', 'confirm', 'confirmed', 'congrats', 'congratulation', 'connect', 'connection', 'considering', 'constantly', 'contact', 'contacted', 'content', 'contract', 'convey', 'cook', 'cooking', 'cool', 'copy', 'cornwall', 'correct', 'cost', 'costa', 'couldn', 'count', 'country', 'couple', 'course', 'cover', 'coz', 'cr', 'crab', 'crack', 'cramp', 'crave', 'crazy', 'cream', 'created', 'credit', 'credited', 'creepy', 'cricketer', 'crisis', 'crore', 'cross', 'croydon', 'cruise', 'csbcm', 'csh', 'ctxt', 'cud', 'cuddle', 'cuddling', 'cum', 'cup', 'curious', 'current', 'currently', 'curry', 'cust', 'custcare', 'custom', 'customer', 'cut', 'cute', 'cutefrnd', 'cuz', 'cw', 'da', 'dad', 'daddy', 'dai', 'daily', 'damn', 'dare', 'dark', 'darlin', 'darling', 'darren', 'dat', 'date', 'datebox', 'dating', 'datz', 'dave', 'day', 'dead', 'deal', 'dear', 'dearer', 'dearly', 'death', 'december', 'decide', 'decided', 'decimal', 'decision', 'deep', 'def', 'definitely', 'del', 'deleted', 'deliver', 'delivered', 'deliveredtomorrow', 'delivery', 'dem', 'den', 'depends', 'derek', 'dey', 'di', 'diamond', 'dick', 'dictionary', 'did', 'didn', 'didnt', 'die', 'died', 'diet', 'diff', 'difference', 'different', 'difficult', 'dificult', 'digital', 'dignity', 'din', 'dinner', 'dint', 'direct', 'directly', 'dirty', 'dis', 'discount', 'discus', 'dislike', 'display', 'distance', 'disturb', 'dload', 'dnt', 'doc', 'doctor', 'doe', 'doesn', 'doesnt', 'dog', 'dogging', 'doggy', 'doin', 'doing', 'dollar', 'don', 'dont', 'door', 'dot', 'double', 'download', 'downloads', 'draw', 'dream', 'dress', 'dressed', 'dresser', 'drink', 'drinking', 'drive', 'drivin', 'driving', 'drop', 'dropped', 'drug', 'drunk', 'dry', 'dsn', 'dubsack', 'dude', 'dun', 'dunno', 'dvd', 'ear', 'earlier', 'early', 'earth', 'easier', 'easy', 'eat', 'eaten', 'eatin', 'eating', 'ec', 'eerie', 'effect', 'egg', 'eh', 'em', 'email', 'embarassed', 'end', 'ended', 'ending', 'enemy', 'energy', 'eng', 'england', 'english', 'enjoy', 'enjoyed', 'enter', 'entered', 'entitled', 'entry', 'enuff', 'envelope', 'er', 'erm', 'error', 'escape', 'ese', 'especially', 'esplanade', 'essential', 'euro', 'eve', 'evening', 'event', 'everybody', 'evn', 'evng', 'evry', 'ex', 'exact', 'exactly', 'exam', 'excellent', 'exciting', 'excuse', 'exe', 'executive', 'exhausted', 'expect', 'expecting', 'expensive', 'experience', 'expires', 'explain', 'express', 'extra', 'eye', 'fa', 'face', 'facebook', 'fact', 'failed', 'fair', 'fall', 'family', 'fan', 'fancy', 'fantastic', 'fantasy', 'far', 'farm', 'fast', 'faster', 'fat', 'father', 'fathima', 'fault', 'fave', 'favor', 'favour', 'favourite', 'fb', 'fear', 'feb', 'february', 'fee', 'feel', 'feelin', 'feeling', 'fell', 'felt', 'female', 'fetch', 'fever', 'fight', 'fighting', 'fightng', 'figure', 'file', 'film', 'final', 'finally', 'fine', 'finger', 'finish', 'finished', 'finishing', 'fish', 'fit', 'fix', 'fixed', 'fl', 'flag', 'flaked', 'flash', 'flat', 'flight', 'flirt', 'floor', 'flower', 'fly', 'fml', 'follow', 'followed', 'following', 'fone', 'food', 'fool', 'foot', 'football', 'footprint', 'force', 'foreign', 'forever', 'forevr', 'forget', 'forgot', 'form', 'forum', 'forward', 'forwarded', 'fr', 'fran', 'freak', 'free', 'freefone', 'freemsg', 'freephone', 'freezing', 'fren', 'frens', 'fri', 'friday', 'friend', 'friendship', 'frm', 'frnd', 'frnds', 'frndship', 'frog', 'fromm', 'frying', 'fuck', 'fucked', 'fuckin', 'fucking', 'ful', 'fullonsms', 'fun', 'function', 'funeral', 'funk', 'funky', 'funny', 'furniture', 'future', 'fwd', 'fyi', 'ga', 'gain', 'gal', 'galileo', 'game', 'gamestar', 'ganesh', 'gang', 'gap', 'garage', 'garbage', 'garden', 'gardener', 'gary', 'gas', 'gastroenteritis', 'gautham', 'gave', 'gay', 'gaytextbuddy', 'gb', 'gbp', 'gd', 'ge', 'gee', 'geeee', 'geeeee', 'gender', 'generally', 'genius', 'gent', 'gentle', 'gentleman', 'gently', 'genuine', 'george', 'germany', 'getstop', 'gettin', 'getting', 'getzed', 'geva', 'gf', 'ghost', 'gift', 'gim', 'girl', 'girlfrnd', 'giv', 'given', 'giving', 'glad', 'gm', 'gn', 'goal', 'god', 'goin', 'going', 'gon', 'gona', 'gone', 'good', 'goodmorning', 'goodnight', 'goodnite', 'google', 'gorgeous', 'gossip', 'got', 'goto', 'govt', 'gr', 'grahmbell', 'gram', 'grand', 'gravity', 'great', 'green', 'greet', 'greeting', 'grin', 'grl', 'ground', 'group', 'gt', 'guaranteed', 'gud', 'gudnite', 'guess', 'guide', 'guilty', 'guy', 'gym', 'ha', 'haf', 'haha', 'hahaha', 'hai', 'hair', 'haiz', 'half', 'halloween', 'ham', 'hand', 'handed', 'handle', 'handset', 'hanging', 'happen', 'happend', 'happened', 'happening', 'happens', 'happiness', 'happy', 'hard', 'hardcore', 'harry', 'hasn', 'hate', 'hav', 'haven', 'havent', 'havin', 'having', 'havnt', 'head', 'headache', 'hear', 'heard', 'heart', 'heavy', 'hee', 'height', 'helen', 'hell', 'hella', 'hello', 'help', 'hey', 'hg', 'hi', 'hide', 'high', 'hill', 'hint', 'hip', 'history', 'hit', 'hiya', 'hl', 'hmm', 'hmmm', 'hmv', 'ho', 'hold', 'holder', 'holding', 'holiday', 'holla', 'hols', 'home', 'homeowner', 'hon', 'honey', 'honeybee', 'hook', 'hop', 'hope', 'hopefully', 'hoping', 'horny', 'horrible', 'hospital', 'hostel', 'hot', 'hotel', 'hour', 'house', 'hows', 'howz', 'hp', 'hr', 'http', 'hubby', 'hug', 'huh', 'hun', 'hungry', 'hunny', 'hurry', 'hurt', 'husband', 'hv', 'hw', 'iam', 'ibhltd', 'ibiza', 'ic', 'ice', 'id', 'idea', 'identifier', 'idiot', 'idk', 'ignore', 'ikea', 'il', 'ill', 'im', 'imagine', 'imma', 'immediately', 'important', 'impossible', 'inch', 'incident', 'include', 'including', 'inclusive', 'india', 'indian', 'infernal', 'info', 'inform', 'information', 'informed', 'inning', 'insha', 'inside', 'instantly', 'instead', 'instituitions', 'instruction', 'insurance', 'intelligent', 'intention', 'interested', 'interesting', 'interflora', 'internet', 'interview', 'intro', 'invader', 'invest', 'invite', 'invited', 'inviting', 'invnted', 'iouri', 'ip', 'ipad', 'ipod', 'iq', 'irritates', 'irritating', 'iscoming', 'ish', 'island', 'isn', 'isnt', 'issue', 'italian', 'itcould', 'item', 'itwhichturnedinto', 'itz', 'ive', 'iz', 'izzit', 'ja', 'jacket', 'jackpot', 'jada', 'james', 'jamster', 'jan', 'jane', 'january', 'japanese', 'jas', 'jason', 'java', 'jay', 'jaya', 'jazz', 'jd', 'jealous', 'jean', 'jen', 'jenny', 'jerry', 'jess', 'jesus', 'jhl', 'jia', 'jiayin', 'jiu', 'jo', 'joanna', 'job', 'jogging', 'john', 'join', 'joined', 'joining', 'joke', 'jokin', 'joking', 'jolly', 'jolt', 'jordan', 'journey', 'joy', 'jsco', 'jst', 'jstfrnd', 'jsut', 'juan', 'juicy', 'july', 'june', 'jus', 'just', 'juz', 'kadeem', 'kaiez', 'kallis', 'kano', 'kappa', 'karaoke', 'kate', 'kavalan', 'kay', 'kb', 'ke', 'keeping', 'kegger', 'kent', 'kept', 'kerala', 'keralacircle', 'kettoda', 'key', 'kg', 'kick', 'kickoff', 'kid', 'kidding', 'kidz', 'kill', 'killed', 'killing', 'kind', 'kinda', 'kindly', 'king', 'kiosk', 'kiss', 'kl', 'knackered', 'knee', 'knew', 'knock', 'know', 'knowing', 'knw', 'konw', 'kothi', 'kr', 'kudi', 'kusruthi', 'kz', 'la', 'lab', 'lac', 'lady', 'lag', 'laid', 'land', 'landline', 'lane', 'langport', 'language', 'laptop', 'lar', 'largest', 'late', 'lately', 'later', 'latest', 'latr', 'laugh', 'laughed', 'laughing', 'laundry', 'law', 'lay', 'lazy', 'lccltd', 'ldew', 'ldn', 'ldnw', 'le', 'lead', 'leaf', 'learn', 'leave', 'leaving', 'lect', 'lecture', 'left', 'leg', 'legal', 'leh', 'lei', 'lem', 'length', 'leona', 'lesson', 'let', 'letter', 'lf', 'liao', 'lib', 'library', 'lick', 'lido', 'lie', 'life', 'lifetime', 'lifpartnr', 'lift', 'light', 'lik', 'like', 'liked', 'likely', 'lil', 'lily', 'limit', 'limiting', 'line', 'linerental', 'link', 'lion', 'lionm', 'lionp', 'lip', 'list', 'listen', 'listening', 'literally', 'little', 'live', 'lived', 'liverpool', 'living', 'lk', 'll', 'lmao', 'lo', 'load', 'loan', 'local', 'location', 'lock', 'log', 'login', 'logo', 'lol', 'london', 'lonely', 'long', 'longer', 'look', 'lookatme', 'looked', 'lookin', 'looking', 'loose', 'lor', 'lose', 'loses', 'losing', 'loss', 'lost', 'lot', 'lotr', 'lotta', 'lou', 'loud', 'lounge', 'lousy', 'lov', 'lovable', 'love', 'loved', 'lovejen', 'lovely', 'loveme', 'lover', 'loverboy', 'loving', 'lovingly', 'low', 'lower', 'loxahatchee', 'loyal', 'loyalty', 'lp', 'lst', 'lt', 'lttrs', 'luck', 'lucky', 'lucozade', 'lucy', 'lunch', 'lush', 'luv', 'luvs', 'lux', 'luxury', 'lv', 'lvblefrnd', 'lyf', 'lyfu', 'lyk', 'ma', 'maangalyam', 'mac', 'machan', 'macho', 'mad', 'madam', 'mag', 'maga', 'magical', 'mah', 'mahal', 'maid', 'mail', 'mailbox', 'main', 'maintain', 'major', 'make', 'makin', 'making', 'malaria', 'male', 'mall', 'man', 'manage', 'managed', 'management', 'manda', 'mandan', 'maneesha', 'map', 'march', 'margaret', 'mark', 'market', 'marriage', 'married', 'marrow', 'marry', 'massage', 'massive', 'master', 'match', 'mate', 'math', 'mathematics', 'matrix', 'matter', 'matured', 'maturity', 'max', 'maximize', 'mayb', 'maybe', 'mb', 'mca', 'mcat', 'meal', 'mean', 'meaning', 'meant', 'measure', 'med', 'medical', 'medicine', 'meet', 'meetin', 'meeting', 'mega', 'meh', 'mei', 'mel', 'melle', 'melt', 'member', 'membership', 'memory', 'men', 'mental', 'menu', 'meow', 'merry', 'mesages', 'mess', 'message', 'messaged', 'messaging', 'messenger', 'messy', 'met', 'mi', 'mid', 'middle', 'midnight', 'mids', 'mila', 'mile', 'milk', 'million', 'min', 'mind', 'mini', 'minimum', 'minmobsmorelkpobox', 'minmoremobsemspobox', 'minnaminunginte', 'minor', 'minute', 'minuts', 'miracle', 'misbehaved', 'miserable', 'miss', 'missed', 'missin', 'missing', 'mistake', 'mite', 'mitsake', 'mix', 'mk', 'ml', 'mm', 'mmm', 'mmmm', 'mmmmm', 'mmmmmm', 'mnth', 'mnths', 'mo', 'moan', 'mob', 'mobile', 'mobilesdirect', 'mobileupd', 'mobno', 'moby', 'mode', 'model', 'module', 'moji', 'mojibiola', 'mokka', 'mom', 'moment', 'mon', 'monday', 'money', 'monkey', 'mono', 'month', 'monthly', 'mood', 'moon', 'moral', 'morefrmmob', 'morn', 'mornin', 'morning', 'moro', 'morow', 'morphine', 'morro', 'morrow', 'mother', 'motorola', 'mountain', 'mouth', 'moved', 'movie', 'movietrivia', 'moving', 'mp', 'mr', 'mrng', 'mrt', 'mrw', 'msg', 'msging', 'msgrcvd', 'msgrcvdhg', 'msn', 'mt', 'mtalk', 'mth', 'mths', 'mtmsg', 'mtmsgrcvd', 'mu', 'muah', 'mum', 'mummy', 'mumtaz', 'munsters', 'murder', 'murdered', 'murderer', 'music', 'musthu', 'muz', 'mystery', 'na', 'nag', 'nagar', 'nah', 'nahi', 'naked', 'nalla', 'named', 'nan', 'nanny', 'nap', 'nasdaq', 'nasty', 'nat', 'natalie', 'natalja', 'national', 'natural', 'nature', 'naughty', 'nb', 'nd', 'ne', 'near', 'nearly', 'necessarily', 'necessary', 'neck', 'necklace', 'ned', 'need', 'needed', 'neft', 'neighbor', 'neighbour', 'nervous', 'net', 'netcollex', 'network', 'networking', 'neva', 'new', 'neway', 'newest', 'news', 'ni', 'nic', 'nice', 'nichols', 'nigeria', 'night', 'nimya', 'nit', 'nite', 'nitros', 'noe', 'nok', 'nokia', 'nokias', 'noline', 'noon', 'nope', 'norm', 'normal', 'normally', 'northampton', 'note', 'nothin', 'notice', 'notxt', 'noun', 'nowadays', 'nt', 'ntt', 'ntwk', 'nu', 'num', 'number', 'nurungu', 'nuther', 'nvm', 'nw', 'nxt', 'ny', 'nyc', 'nydc', 'nyt', 'obviously', 'occupy', 'odi', 'offer', 'office', 'official', 'officially', 'ofice', 'oh', 'oi', 'oic', 'oil', 'ok', 'okay', 'okey', 'okie', 'ola', 'old', 'omg', 'omw', 'oni', 'onion', 'online', 'onwards', 'oooh', 'oops', 'open', 'opening', 'operator', 'opinion', 'opportunity', 'opt', 'option', 'optout', 'orange', 'orchard', 'order', 'ordered', 'oredi', 'oreo', 'orig', 'original', 'oru', 'oso', 'otside', 'outage', 'outside', 'outstanding', 'outta', 'ovulation', 'ow', 'owns', 'oz', 'pa', 'pack', 'package', 'page', 'paid', 'pain', 'painful', 'painting', 'pale', 'pan', 'pandy', 'panic', 'pap', 'paper', 'paperwork', 'paragon', 'parco', 'parent', 'paris', 'park', 'parked', 'parking', 'partner', 'partnership', 'party', 'pas', 'passed', 'passionate', 'password', 'past', 'path', 'pattern', 'patty', 'pay', 'payed', 'payee', 'paying', 'payment', 'payoh', 'pc', 'peace', 'peaceful', 'peak', 'pee', 'pen', 'pending', 'penis', 'penny', 'people', 'percent', 'perfect', 'period', 'permission', 'person', 'personal', 'personality', 'perwksub', 'pete', 'petey', 'petrol', 'pg', 'ph', 'philosophy', 'phne', 'phoenix', 'phone', 'phoned', 'photo', 'php', 'pic', 'pick', 'picked', 'picking', 'pickle', 'picsfree', 'picture', 'pie', 'piece', 'pig', 'pilate', 'pimple', 'pin', 'pink', 'piss', 'pissed', 'pix', 'pizza', 'place', 'placement', 'plan', 'plane', 'planet', 'planned', 'planning', 'play', 'played', 'player', 'playing', 'plaza', 'pleased', 'pleasure', 'plenty', 'plm', 'pls', 'plus', 'plz', 'pm', 'po', 'pobox', 'pocketbabe', 'pod', 'poem', 'point', 'poker', 'pole', 'police', 'politician', 'polo', 'poly', 'polyh', 'polyph', 'polyphonic', 'polys', 'pongal', 'pool', 'poop', 'poor', 'pop', 'popcorn', 'popped', 'porn', 'position', 'possession', 'possible', 'post', 'postcard', 'postcode', 'posted', 'potato', 'potential', 'potter', 'pouch', 'pound', 'pours', 'pout', 'power', 'pp', 'ppermesssubscription', 'ppl', 'pple', 'ppm', 'ppmx', 'ppw', 'prabha', 'practical', 'practice', 'practicing', 'pray', 'praying', 'pre', 'prefer', 'preferably', 'prem', 'premier', 'premium', 'prepaid', 'prepare', 'prepared', 'prepayment', 'prescription', 'present', 'press', 'pretty', 'previous', 'previously', 'prey', 'price', 'pride', 'prince', 'princess', 'print', 'printed', 'priscilla', 'privacy', 'private', 'prize', 'pro', 'prob', 'probably', 'problem', 'probs', 'process', 'processed', 'prof', 'professor', 'profile', 'profit', 'program', 'project', 'prolly', 'promise', 'promo', 'prompt', 'proof', 'properly', 'property', 'propose', 'propsd', 'prospect', 'protect', 'prove', 'proverb', 'provided', 'pt', 'ptbo', 'pub', 'public', 'pull', 'purchase', 'purity', 'purpose', 'purse', 'push', 'pussy', 'puttin', 'putting', 'pw', 'px', 'qatar', 'qp', 'qu', 'quality', 'queen', 'ques', 'question', 'questioned', 'quick', 'quickly', 'quiet', 'quit', 'quite', 'quiz', 'quote', 'quoting', 'qxj', 'racing', 'radio', 'raed', 'rael', 'railway', 'rain', 'raining', 'raise', 'raj', 'raji', 'rakhesh', 'rally', 'ran', 'random', 'randomly', 'randy', 'rang', 'range', 'ranjith', 'rate', 'ray', 'rcv', 'rcvd', 'rd', 'reach', 'reached', 'reaching', 'reaction', 'read', 'reader', 'reading', 'ready', 'real', 'realise', 'reality', 'realize', 'realized', 'really', 'realy', 'reason', 'reasonable', 'reboot', 'rec', 'recd', 'receipt', 'receive', 'receivea', 'received', 'receiving', 'recent', 'recently', 'recession', 'recharge', 'reckon', 'recognise', 'record', 'recovery', 'red', 'redeemed', 'reduce', 'ref', 'reference', 'refilled', 'refused', 'reg', 'regard', 'regarding', 'register', 'registered', 'regret', 'regular', 'relation', 'relative', 'relax', 'released', 'rem', 'remain', 'remains', 'remember', 'remembered', 'remembr', 'remind', 'reminder', 'reminding', 'removal', 'remove', 'removed', 'renewal', 'rent', 'rental', 'rentl', 'repair', 'repeat', 'replace', 'replacement', 'replied', 'reply', 'replying', 'report', 'representative', 'request', 'research', 'reserve', 'respect', 'respectful', 'responce', 'respond', 'responding', 'response', 'responsibility', 'rest', 'restaurant', 'result', 'resume', 'retrieve', 'return', 'returned', 'reveal', 'revealed', 'reverse', 'review', 'revision', 'reward', 'rewarding', 'rg', 'rgds', 'rhythm', 'rice', 'rich', 'ride', 'right', 'rightly', 'ring', 'ringtone', 'ringtoneking', 'ringtones', 'risk', 'rite', 'river', 'road', 'roast', 'rock', 'rofl', 'roger', 'role', 'romantic', 'ron', 'room', 'roommate', 'rose', 'round', 'row', 'royal', 'rply', 'rr', 'rstm', 'ru', 'rub', 'rude', 'ruin', 'ruining', 'rule', 'rum', 'rumour', 'run', 'running', 'rush', 'rw', 'ryan', 'sac', 'sachin', 'sacrifice', 'sad', 'sae', 'safe', 'said', 'sake', 'salam', 'salary', 'sale', 'salon', 'sam', 'santa', 'sar', 'sarasota', 'sarcasm', 'sarcastic', 'sary', 'sat', 'sathya', 'satisfied', 'satisfy', 'saturday', 'saucy', 'savamob', 'save', 'saved', 'saw', 'say', 'saying', 'scared', 'scary', 'sch', 'schedule', 'school', 'science', 'scold', 'score', 'scoring', 'scotch', 'scotland', 'scotsman', 'scream', 'screamed', 'screaming', 'screen', 'scrounge', 'sd', 'se', 'sea', 'search', 'searching', 'season', 'seat', 'sec', 'second', 'secret', 'secretary', 'secretly', 'section', 'sed', 'seed', 'seeing', 'seen', 'select', 'selected', 'selection', 'self', 'selfish', 'sell', 'selling', 'sem', 'semester', 'sen', 'send', 'sender', 'sending', 'sends', 'sense', 'sensitive', 'sent', 'sentence', 'senthil', 'sept', 'series', 'seriously', 'service', 'serving', 'set', 'setting', 'settle', 'settled', 'seven', 'sex', 'sexy', 'sh', 'sha', 'shagged', 'shahjahan', 'shall', 'shame', 'shampain', 'share', 'shared', 'sharing', 'shd', 'sheet', 'sheffield', 'shelf', 'shesil', 'shijas', 'shining', 'ship', 'shipped', 'shipping', 'shirt', 'shit', 'shitload', 'shld', 'shock', 'shocking', 'shoe', 'shoot', 'shop', 'shoppin', 'shopping', 'shore', 'short', 'shortage', 'shorter', 'shortly', 'shot', 'shouldn', 'shouted', 'shoving', 'shower', 'showing', 'shracomorsglsuplt', 'shu', 'shuhui', 'shut', 'shy', 'si', 'sian', 'sib', 'sick', 'sigh', 'sight', 'sign', 'signing', 'silence', 'silent', 'silently', 'silver', 'sim', 'simple', 'simpler', 'simply', 'sinco', 'sing', 'singing', 'single', 'sip', 'sipix', 'sir', 'sister', 'sit', 'site', 'sitll', 'sitting', 'situation', 'siva', 'size', 'sk', 'skilgme', 'skillgame', 'skip', 'sky', 'skype', 'skyped', 'slap', 'slave', 'sleep', 'sleepin', 'sleeping', 'slept', 'slice', 'slipper', 'slow', 'slowly', 'sm', 'small', 'smart', 'smile', 'smiling', 'smoke', 'smoking', 'smth', 'sn', 'snake', 'snow', 'social', 'sofa', 'soft', 'software', 'sol', 'solve', 'somebody', 'somethin', 'song', 'sony', 'sonyericsson', 'soon', 'sooner', 'sore', 'sorrow', 'sorry', 'sort', 'sorted', 'sorting', 'sory', 'soryda', 'sound', 'soup', 'source', 'south', 'sp', 'space', 'spanish', 'spare', 'speak', 'special', 'specially', 'speechless', 'speed', 'spell', 'spend', 'spending', 'spent', 'spk', 'spl', 'spoke', 'spoken', 'spook', 'sport', 'spree', 'spring', 'sry', 'st', 'staff', 'stamp', 'stand', 'standard', 'standing', 'star', 'start', 'started', 'starting', 'starwars', 'statement', 'station', 'stay', 'staying', 'std', 'step', 'stock', 'stockport', 'stomach', 'stomp', 'stone', 'stop', 'stopped', 'stoptxt', 'store', 'storming', 'story', 'str', 'straight', 'stranger', 'street', 'stress', 'stretch', 'strike', 'strip', 'strong', 'stuck', 'student', 'study', 'studying', 'stuff', 'stupid', 'style', 'stylish', 'sub', 'subpoly', 'subscribe', 'subscribed', 'subscriber', 'subscription', 'successful', 'successfully', 'suck', 'sugar', 'suggest', 'suite', 'sum', 'summer', 'sun', 'sunday', 'sunny', 'sunshine', 'suntec', 'sup', 'super', 'superb', 'superior', 'supervisor', 'supply', 'support', 'supposed', 'suprman', 'sura', 'sure', 'surely', 'surfing', 'surprise', 'surprised', 'sw', 'sweet', 'sweetest', 'swimming', 'swing', 'switch', 'swt', 'swtheart', 'symbol', 'ta', 'table', 'tablet', 'taken', 'takin', 'taking', 'talent', 'talk', 'talking', 'tampa', 'tape', 'tariff', 'tat', 'taunton', 'taylor', 'tb', 'tc', 'tcr', 'tea', 'teach', 'teacher', 'team', 'tear', 'tease', 'teasing', 'technical', 'teeth', 'tel', 'tell', 'telling', 'telphone', 'temp', 'temple', 'tenant', 'tenerife', 'term', 'terrible', 'tessy', 'test', 'text', 'textcomp', 'texted', 'texting', 'textoperator', 'textpod', 'tf', 'th', 'thangam', 'thank', 'thanks', 'thanksgiving', 'thanx', 'thats', 'theatre', 'themob', 'theory', 'thing', 'think', 'thinkin', 'thinking', 'thk', 'thm', 'thnk', 'tho', 'thought', 'threat', 'throat', 'throw', 'tht', 'thts', 'thurs', 'thursday', 'ti', 'tick', 'ticket', 'tihs', 'til', 'till', 'time', 'timing', 'tired', 'tirupur', 'title', 'tkts', 'tlp', 'tm', 'tmr', 'tncs', 'toa', 'toclaim', 'today', 'tog', 'told', 'toll', 'tom', 'tomarrow', 'tomo', 'tomorrow', 'tone', 'tonight', 'tonite', 'took', 'torch', 'tot', 'total', 'totally', 'touch', 'touched', 'tough', 'tour', 'town', 'track', 'trade', 'traffic', 'train', 'training', 'transaction', 'transfer', 'transfered', 'travel', 'treat', 'treated', 'tree', 'tried', 'trip', 'trouble', 'truck', 'true', 'truffle', 'truly', 'trust', 'truth', 'try', 'trying', 'tsandcs', 'tscs', 'tsunami', 'tt', 'ttyl', 'tues', 'tuesday', 'tuition', 'turn', 'tv', 'twice', 'txt', 'txtauction', 'txtin', 'txting', 'txts', 'tyler', 'type', 'tyrone', 'ubi', 'ugh', 'uk', 'umma', 'ummmmmaah', 'unable', 'uncle', 'understand', 'understanding', 'understood', 'uni', 'unique', 'university', 'unless', 'unlimited', 'unredeemed', 'unsold', 'unsub', 'unsubscribe', 'update', 'upgrade', 'upload', 'upset', 'upto', 'ur', 'urawinner', 'ure', 'urgent', 'urgently', 'urgnt', 'url', 'urn', 'urself', 'usc', 'use', 'used', 'user', 'usf', 'using', 'usual', 'usually', 'uz', 'vaazhthukkal', 'vale', 'valentine', 'valid', 'valuable', 'value', 'valued', 'various', 'vary', 'vava', 'vday', 've', 'vega', 'vegetable', 'verified', 'verify', 'version', 'vettam', 'vewy', 'vid', 'video', 'videochat', 'videophones', 'vijay', 'vikky', 'village', 'violated', 'violence', 'violet', 'vip', 'virgin', 'visionsms', 'visit', 'visitor', 'viva', 'vivek', 'vl', 'voda', 'vodafone', 'vodka', 'voice', 'voicemail', 'vomit', 'vomiting', 'vote', 'voucher', 'vry', 'vth', 'vu', 'wa', 'wah', 'waheed', 'waht', 'wait', 'waited', 'waitin', 'waiting', 'wake', 'waking', 'wale', 'walk', 'walked', 'walking', 'wall', 'wallpaper', 'walmart', 'wan', 'wana', 'want', 'wanted', 'wanting', 'wap', 'warm', 'warner', 'warning', 'warranty', 'wasn', 'waste', 'wasted', 'wat', 'watch', 'watching', 'water', 'watever', 'wating', 'wats', 'wave', 'waxsto', 'way', 'wb', 'wc', 'weak', 'weakness', 'wear', 'wearing', 'weather', 'web', 'website', 'wed', 'wedding', 'wednesday', 'wee', 'weed', 'week', 'weekend', 'weekly', 'weigh', 'weight', 'weird', 'weirdest', 'welcome', 'welp', 'wen', 'went', 'wer', 'wesley', 'west', 'westlife', 'wet', 'whats', 'whatsup', 'whenevr', 'white', 'whn', 'whr', 'wicklow', 'wid', 'widelive', 'wif', 'wife', 'wifi', 'wihtuot', 'wil', 'willing', 'win', 'winaweek', 'winawk', 'wind', 'window', 'wine', 'winner', 'winning', 'wipro', 'wisdom', 'wise', 'wish', 'wishin', 'wishing', 'wiskey', 'wit', 'wiv', 'wk', 'wkend', 'wkent', 'wkg', 'wkly', 'wks', 'wld', 'wml', 'wn', 'wnt', 'wo', 'woke', 'woken', 'woman', 'won', 'wonder', 'wonderful', 'wondering', 'wont', 'woot', 'word', 'work', 'workin', 'working', 'world', 'worried', 'worry', 'worse', 'worst', 'worth', 'wot', 'woulda', 'wouldn', 'wow', 'wp', 'wq', 'wrc', 'write', 'wrk', 'wrnog', 'wrong', 'wrote', 'wt', 'wtf', 'wu', 'wud', 'wuld', 'wun', 'www', 'wx', 'wylie', 'xam', 'xavier', 'xchat', 'xh', 'xin', 'xmas', 'xn', 'xuhui', 'xx', 'xxx', 'xxxmobilemovieclub', 'xxxx', 'xxxxx', 'xxxxxx', 'xxxxxxx', 'xxxxxxxxx', 'xy', 'ya', 'yahoo', 'yan', 'yar', 'yarasu', 'yay', 'yck', 'yeah', 'year', 'yeh', 'yelling', 'yellow', 'yep', 'yer', 'yes', 'yest', 'yesterday', 'yetunde', 'yf', 'yijue', 'ym', 'yo', 'yoga', 'yogasana', 'yor', 'youre', 'yr', 'yummy', 'yun', 'yunny', 'yuo', 'yup', 'zed', 'zindgi', 'zoe']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "max_features = 3000\n",
    "count_vectorizer = CountVectorizer(max_features = max_features, stop_words = \"english\")\n",
    "sparce_matrix = count_vectorizer.fit_transform(description_list).toarray()\n",
    "print(\"Самые часто встречаемые {} слов: {}\".format(max_features,count_vectorizer.get_feature_names()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чаще всего во всех сообщениях встречается слово 'crazy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "pH1JagoUelrD",
    "outputId": "40052921-4c09-4161-f91e-847e5419b63b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "592\n"
     ]
    }
   ],
   "source": [
    "list_names = count_vectorizer.get_feature_names()\n",
    "for i in range(len(list_names)):\n",
    "    if list_names[i] == 'crazy':\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wbDY56XWV7do"
   },
   "source": [
    "Исходные данные преобразуем в bag-of-words формат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "uJB0dstJfO7J",
    "outputId": "257b248e-7c2f-43a0-b44c-180930b6e01c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparce_matrix[0, 592]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "k8yCXDOfWAww",
    "outputId": "cba53e0e-5d41-4385-8e96-a8df9ec72589"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000\n"
     ]
    }
   ],
   "source": [
    "print(len(sparce_matrix[0,: ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9e24S-P4Vsrr"
   },
   "outputs": [],
   "source": [
    "y = data.iloc[:,0].values\n",
    "x = sparce_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dCv03et0WW5L"
   },
   "source": [
    "Делим данные на тренировочные и тестовые"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rF67b7VdV2VK"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size = 0.2, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tFi1KFI8WaWS"
   },
   "source": [
    "Напишем **наивный байесовский классификатор**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Ls-QwJfpWNVH",
    "outputId": "9aeb4a8e-899d-4b7d-e277-c91e0f230391"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the accuracy of our model: 0.8753363228699551\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb = GaussianNB()\n",
    "nb.fit(x_train,y_train)\n",
    "print(\"the accuracy of our model: {}\".format(nb.score(x_test,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "u9D5KTE6h19S",
    "outputId": "d5f5aca2-1a57-47a1-ed15-33a73a7c68eb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.87      0.92       966\n",
      "           1       0.52      0.89      0.66       149\n",
      "\n",
      "    accuracy                           0.88      1115\n",
      "   macro avg       0.75      0.88      0.79      1115\n",
      "weighted avg       0.92      0.88      0.89      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, nb.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hRdUt0ThWe30"
   },
   "source": [
    "Напишем логистическую регрессию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 88
    },
    "colab_type": "code",
    "id": "epQOa7FRWhqS",
    "outputId": "a27256ad-c076-4170-e7de-b8768fa35ba8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "our accuracy is: 0.9820627802690582\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(max_iter = 200)\n",
    "lr.fit(x_train,y_train)\n",
    "print(\"our accuracy is: {}\".format(lr.score(x_test,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "LNyFu4X1iabe",
    "outputId": "77ef3195-b21d-4b15-96b5-9d4595bb8d19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99       966\n",
      "           1       1.00      0.87      0.93       149\n",
      "\n",
      "    accuracy                           0.98      1115\n",
      "   macro avg       0.99      0.93      0.96      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, lr.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cWc_Fs10W71Y"
   },
   "source": [
    "Классификатор по методу ближайшего соседа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "-05vUVlPW6Ey",
    "outputId": "96718b84-2014-4f48-a713-3964037917b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With KNN (K=3) accuracy is:  0.9399103139013453\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "knn.fit(x_train,y_train)\n",
    "#print('Prediction: {}'.format(prediction))\n",
    "print('With KNN (K=3) accuracy is: ',knn.score(x_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "id": "dIrdoC-7igLs",
    "outputId": "b2da12cd-3931-40e0-a1d9-e12002f1db1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97       966\n",
      "           1       1.00      0.55      0.71       149\n",
      "\n",
      "    accuracy                           0.94      1115\n",
      "   macro avg       0.97      0.78      0.84      1115\n",
      "weighted avg       0.94      0.94      0.93      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, knn.predict(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZSGytE8OisyJ"
   },
   "source": [
    "Из всех выбранных моделей лучше всего дала результаты модель логистической регрессии."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ri6UgBXQoBnb"
   },
   "source": [
    "# Задача - определить класс, к которому относится тот или иной текст"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RnbwL_5mrS8U"
   },
   "source": [
    "Удаляем слова, которые не имеют смысловой нагрузки (например, слова 'и', 'или', 'а' и другие)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "oQvN2BL-ojtl",
    "outputId": "4ecec07f-4c6e-4234-b7fd-2c9450b24c7a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/yustinaivanova/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "import string\n",
    "import re\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def remove_stopwords(line):\n",
    "    word_tokens = word_tokenize(line)\n",
    "    filtered_sentence = [w for w in word_tokens if not w in stop_words] \n",
    "    return \" \".join(filtered_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sbMjGkOgr4QA"
   },
   "source": [
    "Далее функция, с помощью которой мы будем обрабатывать твиты\n",
    "\n",
    "\n",
    "*   переводим все слова в строчные буквы\n",
    "*   удаляем цифры\n",
    "*   удаляем пунктуацию\n",
    "*   удаляем стоп-слова\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3qfvy75XrDtU"
   },
   "outputs": [],
   "source": [
    "def preprocess(line):\n",
    "  # все слова переводим в строчный текст\n",
    "    line = line.lower()\n",
    "  # удаляем цифры\n",
    "    line = re.sub(r'\\d+', '', line)\n",
    "  # удаляем пунктуацию\n",
    "    line = line.translate(line.maketrans(\"\",\"\", string.punctuation))\n",
    "    line = remove_stopwords(line)\n",
    "    return line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z-I5nlmNsmpZ"
   },
   "source": [
    "Предобработка всех твитов из таблицы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "eHtyWq8NrA8H",
    "outputId": "b34dd777-5531-4878-e459-fc4a7e76ab02"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yustinaivanova/venv/venv/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "train = data\n",
    "\n",
    "for i,line in enumerate(train.tweet):\n",
    "    train.tweet[i] = preprocess(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>user father dysfunctional selfish drags kids d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>user user thanks lyft credit cant use cause do...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday majesty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>model love u take u time urð± ðððð...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>factsguide society motivation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31957</th>\n",
       "      <td>31958</td>\n",
       "      <td>0</td>\n",
       "      <td>ate user isz youuuððððððð...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31958</th>\n",
       "      <td>31959</td>\n",
       "      <td>0</td>\n",
       "      <td>see nina turner airwaves trying wrap mantle ge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31959</th>\n",
       "      <td>31960</td>\n",
       "      <td>0</td>\n",
       "      <td>listening sad songs monday morning otw work sad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31960</th>\n",
       "      <td>31961</td>\n",
       "      <td>1</td>\n",
       "      <td>user sikh temple vandalised calgary wso condem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31961</th>\n",
       "      <td>31962</td>\n",
       "      <td>0</td>\n",
       "      <td>thank user follow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31962 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  label                                              tweet\n",
       "0          1      0  user father dysfunctional selfish drags kids d...\n",
       "1          2      0  user user thanks lyft credit cant use cause do...\n",
       "2          3      0                                     bihday majesty\n",
       "3          4      0  model love u take u time urð± ðððð...\n",
       "4          5      0                      factsguide society motivation\n",
       "...      ...    ...                                                ...\n",
       "31957  31958      0  ate user isz youuuððððððð...\n",
       "31958  31959      0  see nina turner airwaves trying wrap mantle ge...\n",
       "31959  31960      0    listening sad songs monday morning otw work sad\n",
       "31960  31961      1  user sikh temple vandalised calgary wso condem...\n",
       "31961  31962      0                                  thank user follow\n",
       "\n",
       "[31962 rows x 3 columns]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JqH38PT5sb47"
   },
   "source": [
    "Разделим датасет на тренировочный и тестовый"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "xqF08sLBsapA",
    "outputId": "1cdd02bb-6a53-4d7e-e37b-3ebc683f61b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2242 entries, 13 to 31960\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   id      2242 non-null   int64 \n",
      " 1   label   2242 non-null   int64 \n",
      " 2   tweet   2242 non-null   object\n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 70.1+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 29720 entries, 0 to 31961\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   id      29720 non-null  int64 \n",
      " 1   label   29720 non-null  int64 \n",
      " 2   tweet   29720 non-null  object\n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 928.8+ KB\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train['tweet'], train['label'], \n",
    "                                                    test_size=0.5, stratify=train['label'])\n",
    "\n",
    "trainp=train[train.label==1]\n",
    "trainn=train[train.label==0]\n",
    "print(trainp.info())\n",
    "trainn.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MEBfXJvFstxJ"
   },
   "source": [
    "Можно заметить, что классы **несбалансированы**: в классе 1 2242 элемента, а в классе 0 их 29720. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jZzvozfItINL"
   },
   "source": [
    "Создадим bag-of-words вектора для всех твитов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jNcOfFrDtNoU"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "vect = CountVectorizer()\n",
    "tf_train=vect.fit_transform(X_train)  #train the vectorizer, build the vocablury\n",
    "tf_test=vect.transform(X_test)  #get same encodings on test data as of vocabulary built"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Xz_uoxWUtRJl"
   },
   "source": [
    "Создадим модель **Наивный байес**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EcwwEUNHtTA7"
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "model = MultinomialNB()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jdihWKR6tlbR"
   },
   "source": [
    "Обучим модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "lpthYn7htjiG",
    "outputId": "d7bfa8ba-a61f-49d5-b306-52a5d386b5b6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X=tf_train,y=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wOKUfO3JtoKC"
   },
   "source": [
    "Посмотрим качество модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "x--lPL7Jtosu",
    "outputId": "bb7dca9f-aca6-4953-c339-d2108ae34e7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98     14860\n",
      "           1       0.89      0.43      0.58      1121\n",
      "\n",
      "    accuracy                           0.96     15981\n",
      "   macro avg       0.92      0.71      0.78     15981\n",
      "weighted avg       0.95      0.96      0.95     15981\n",
      "\n",
      "[[14798    62]\n",
      " [  642   479]]\n"
     ]
    }
   ],
   "source": [
    "expected = y_test\n",
    "predicted=model.predict(tf_test)\n",
    "from sklearn import metrics\n",
    "\n",
    "print(metrics.classification_report(expected, predicted))\n",
    "print(metrics.confusion_matrix(expected, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e5hNKWCVtzkb"
   },
   "source": [
    "Можно заметить, что класс 1 предсказывается намного хуже, чем класс 0: класса 1 намного меньше по числу элементов, чем класс 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EkZX9ROIt_1f"
   },
   "source": [
    "Сбалансируем датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "id": "mnkYC-snuOHP",
    "outputId": "77fa6a69-6116-4913-ee62-093180fc751d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before\n",
      "0    29720\n",
      "1     2242\n",
      "Name: label, dtype: int64\n",
      "After\n",
      "1    29720\n",
      "0    29720\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_imbalanced = train\n",
    "from sklearn.utils import resample\n",
    "df_majority = train[train.label==0]\n",
    "df_minority = train[train.label==1]\n",
    " \n",
    "# Upsample minority class\n",
    "df_minority_upsampled = resample(df_minority, \n",
    "                                 replace=True,     # sample with replacement\n",
    "                                 n_samples=len(df_majority),    # to match majority class\n",
    "                                 random_state=123) # reproducible results\n",
    " \n",
    "# Combine majority class with upsampled minority class\n",
    "df_upsampled = pd.concat([df_majority, df_minority_upsampled])\n",
    " \n",
    "# Display new class counts\n",
    "print(\"Before\")\n",
    "print(train.label.value_counts())\n",
    "print(\"After\")\n",
    "print(df_upsampled.label.value_counts())\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_upsampled['tweet'], df_upsampled['label'], test_size=0.5, stratify=df_upsampled['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QwutTun8xX2I"
   },
   "source": [
    "Можно заметить, что тренировочных данных стало больше, и классы уравнялись в количестве."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "NoD2ivRazam6",
    "outputId": "a4b034e7-53ee-4349-d67d-629f48fe2188"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.92      0.94     14860\n",
      "           1       0.92      0.97      0.94     14860\n",
      "\n",
      "    accuracy                           0.94     29720\n",
      "   macro avg       0.94      0.94      0.94     29720\n",
      "weighted avg       0.94      0.94      0.94     29720\n",
      "\n",
      "Матрица confusion\n",
      "[[13612  1248]\n",
      " [  458 14402]]\n"
     ]
    }
   ],
   "source": [
    "tf_train=vect.transform(X_train)\n",
    "tf_test=vect.transform(X_test)\n",
    "model.fit(X=tf_train,y=y_train)\n",
    "expected = y_test\n",
    "predicted=model.predict(tf_test)\n",
    "from sklearn import metrics\n",
    "\n",
    "print(metrics.classification_report(expected, predicted))\n",
    "print('Матрица confusion')\n",
    "print(metrics.confusion_matrix(expected, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GA-HqiesgQGd"
   },
   "source": [
    "Можно заметить, что балансировка привела к улучшению результата."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "4hzAP6kG0qCb",
    "J0t8bCoH8rIS"
   ],
   "include_colab_link": true,
   "name": "lecture_5.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
